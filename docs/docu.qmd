---
title: Documentation
format: html
---

# 1. Introduction

Le projet **CycleVision3** a pour objectif d’analyser et de prédire les flux cyclistes dans la ville de Montpellier à l’aide de données issues de trois sources principales :  

- **VéloMagg** : Historique des trajets réalisés avec le système de vélos en libre-service.  
- **Capteurs de flux cyclistes et piétons** : Données collectées à partir de dispositifs installés aux points stratégiques de la ville.  
- **OpenStreetMap (OSM)** : Données géographiques ouvertes, utilisées pour la cartographie et la contextualisation des trajets.  

L’ambition du projet est de développer des **visualisations interactives**, notamment une **carte prédictive des flux cyclistes**, accessibles via un site web dédié. Ces outils visent à :  
- **Identifier les tendances de mobilité** pour mieux comprendre les habitudes des usagers.  
- **Proposer des solutions pratiques** afin d’optimiser les infrastructures urbaines et de promouvoir l’usage du vélo comme moyen de transport durable.  

En combinant innovation technologique et impact sociétal, **CycleVision3** s’inscrit dans une démarche adaptable à d’autres contextes urbains. Ce projet contribue ainsi à la réflexion autour de la mobilité intelligente et durable, répondant aux enjeux croissants des villes contemporaines.

# 2. Project Setup

## 2.1 Structure du projet [WILL BE FINISHED AT THE END]

La structure du projet est conçue pour garantir une séparation claire des composantes essentielles à l’analyse et à la création des visualisations. Voici un aperçu de l’organisation des fichiers et répertoires :

<details> <summary>Voir le structure</summary>

```
main/                                           # Répertoire principal du projet
├── .github/workflows/                          # Configuration pour l'intégration continue
├── analyse_donnee/                             # Scripts pour l'analyse des données
├── cache/                                      # Fichiers temporaires
├── data/                                       # Données des 3 jeux de données
│   ├── extracted/                              # Données extraites
│   ├── CoursesVelomagg.csv                     # Données des trajets VéloMagg
│   ├── video.csv                               # Données vidéo brutes
│   └── video_avec_coord.csv                    # Données vidéo enrichies avec coordonnées
├── docs/                                       # Répertoire des fichiers du site web
│   ├── .gitignore                              # Liste des fichiers à ignorer par Git
│   ├──                                         # 
│   ├──                                         # 
│   ├──                                         # 
│   └── styles.css                              # Fichier CSS pour la mise en forme du site
├── images/                                     # Images utilisées dans le projet
├── map/                                        # Scripts pour les cartes interactives
├── roadmap/                                    # Fichier README.md avec la description .......
├── slide/                                      # 
├── src/                                        # Répertoire contenant le code source
│   ├── __init__.py                             # Initialisation du package
│   ├── donnée.py                               # Fonctions de traitement des données
│   └── fonctions_basedonnees.py                # Fonctions pour les bases de données
├── vidéo/                                      # 
├── visualisation/                              # Résultats des visualisations
├──.DS_Store                                    # 
├──
├──
├── .Rhistory                                   # Fichier d'historique R
├── .gitignore                                  # Fichier Git ignore
├── README.md                                   # Documentation principale du projet
└── requirements.txt                            # Dépendances du projet
```
</details>

## 2.2 Installation et dépendances

Avant de commencer le développement et l'analyse des données, il est nécessaire de configurer l'environnement de travail en installant toutes les dépendances nécessaires. Voici les étapes à suivre pour préparer le projet :

### Étapes de Préparation :
1. **Cloner le Dépôt Git** :  
   Téléchargez le projet en exécutant :
   ```bash
   git clone https://github.com/mscaia/PROJ_HAX712X.git
   ```

2. **Installer les Dépendances** :  
   Installez les bibliothèques nécessaires :
   ```bash
   pip install -r requirements.txt
   ```

3. **Prévisualiser le Site Web** :  
   Vérifiez l’environnement en lançant le serveur Quarto :
   ```bash
   quarto preview
   ```

## 2.3 Configuration des fichiers [**Sphinx** - CHEKED]

Le projet est configuré de manière à utiliser **Quarto** pour la création du site web interactif et [**Sphinx** pour la documentation générée automatiquement]. Le fichier `_quarto.yml` contient les paramètres de configuration du projet Quarto, tandis que le fichier `index.qmd` contient le contenu principal de la page d'accueil du site.

## 2.4 Base de données et traitement des données [SHOULD BE RECHEKED AFTER]

Les principaux jeux de données sont stockés dans le répertoire `data/` et comprennent :
- **CoursesVelomagg.csv** : Historique des trajets en vélos libres.  
- **video.csv** et **video_avec_coord.csv** : Données vidéo pour l’analyse spatiale.

Les scripts situés dans `src/` effectuent :
- Le nettoyage des données.  
- La conversion des formats pour l’analyse.  

## 2.5 Exécution du projet

L’exécution du projet génère des visualisations interactives et des cartes prédictives grâce à :
- **Folium** : Création de cartes interactives.  
- **Matplotlib** : Graphiques statistiques.  

Les résultats sont stockés dans `visualisation/` et incluent des cartes des trajets et des prévisions de trafic.

## 2.6 Documentation et tests [FINISH AND RECHECKED]

Pour garantir la qualité du code, le projet intègre :
- **Tests Unitaires** : Vérification des fonctionnalités principales.  
- **Documentation Technique** : Générée avec **Sphinx** et **Quarto** pour détailler les API, les méthodes et les résultats.

# 3. Description des Données [RECHECK ABOOUT THE DATASETS WITH TEAM]

L’analyse repose sur l’exploitation de trois ensembles de données principaux, chacun jouant un rôle clé dans l’étude des trajets cyclistes à Montpellier :

- **Données des trajets en vélos en libre-service (VéloMagg)** : Ces données fournissent des informations détaillées sur l’utilisation des vélos en libre-service dans la métropole de Montpellier. Elles constituent une base essentielle pour analyser les tendances et les flux de déplacements cyclistes.  
  *Source*: [Trajets à vélos en libre-service](https://data.montpellier3m.fr/dataset/courses-des-velos-velomagg-de-montpellier-mediterranee-metropole)  

- **Données de comptage cycliste et piéton** : Ces données, collectées par des capteurs placés à divers emplacements stratégiques, permettent de mesurer les flux de cyclistes et de piétons dans la ville. Elles enrichissent l'analyse en fournissant une perspective quantitative sur la fréquentation des infrastructures.  
  *Source*: [Comptages vélo et piéton issus des compteurs de vélo](https://data.montpellier3m.fr/dataset/comptages-velo-et-pieton-issus-des-compteurs-de-velo)  

- **Données géographiques OpenStreetMap (OSM)** : Ces données géographiques offrent une cartographie précise des rues, pistes cyclables et points d’intérêt de la ville. Elles sont cruciales pour la visualisation et la spatialisation des trajets étudiés.  
  *Source*: [OpenStreetMap](https://www.openstreetmap.org/#map=6/46.45/2.21)  

Ces trois ensembles de données, complémentaires par nature, permettent une analyse approfondie et multidimensionnelle du trafic cycliste à Montpellier.
# 4. Workflow du Projet

## 4.1 Prétraitement et Nettoyage des Données

#### Étapes réalisées :
Le nettoyage et le prétraitement des données ont constitué une étape fondamentale pour assurer la qualité et la cohérence des données utilisées dans l’analyse. Les principales actions entreprises sont les suivantes :
- **Validation des données** : Identification et traitement des anomalies, telles que les valeurs aberrantes et les doublons, avec une gestion des valeurs manquantes en fonction de leur impact sur l’analyse.
- **Formatage temporel et géographique** : Conversion des champs de dates pour permettre une analyse chronologique, et standardisation des adresses et coordonnées géographiques pour optimiser la géolocalisation.

Cette phase a permis de préparer des données propres et fiables, essentielles pour l’analyse et la création des visualisations.

## 4.2 Visualisation et Cartographie du Trafic

#### Étapes réalisées :
Les données traitées ont été intégrées dans des visualisations interactives et des cartes dynamiques pour illustrer le trafic cycliste à Montpellier. Les actions clés incluent :
- **Création de cartes interactives** : Utilisation de la bibliothèque `Folium` pour développer une carte dynamique présentant les stations de vélos, les itinéraires fréquentés, et les zones de densité de trafic.
- **Calcul des itinéraires** : Emploi de la bibliothèque `OSMnx` pour déterminer les itinéraires entre les stations, mettant en évidence les parcours les plus utilisés et permettant l’analyse des variations temporelles du trafic.

Ces visualisations ont été des outils essentiels pour la compréhension des tendances du trafic cycliste, facilitant l’analyse et la prise de décisions éclairées pour les phases suivantes du projet.

## 4.3 Développement de l’Interface Web

Le projet s’est concrétisé par la création d’un site web interactif développé avec `Quarto`, intégrant :
- Les visualisations interactives produites lors de l’analyse.
- Une carte prédictive du trafic cycliste, permettant d’estimer les flux de vélos pour le lendemain en fonction des données historiques.

Cette interface a été conçue pour offrir une navigation fluide et intuitive, rendant les résultats accessibles aux utilisateurs de vélos. Elle constitue un outil complet pour l’analyse des données et la planification urbaine, tout en favorisant la promotion de la mobilité durable.

# 5. Pipeline de Traitement des Données

Le traitement des données est un élément central du projet **CycleVision3**, transformant les données brutes en informations exploitables pour l’analyse et la modélisation du trafic cycliste. La méthodologie adoptée repose sur une structure modulaire, garantissant flexibilité et robustesse. Les étapes principales du pipeline sont détaillées ci-dessous :

## 5.1 Acquisition des données

Les ensembles de données ont été obtenus à partir de sources officielles :

- **Données VéloMagg** : Historique des trajets réalisés via le système de vélos en libre-service.
- **Comptages cyclistes et piétons** : Données de comptage obtenues par des capteurs installés à des points stratégiques de la ville.
- **Données OpenStreetMap (OSM)** : Informations géographiques utilisées pour la cartographie des trajets.

Les fichiers ont été extraits sous les formats `.csv` et `.json` et chargés à l’aide de la bibliothèque `pandas`. Une validation initiale a été réalisée pour vérifier l’intégrité des fichiers (taille, colonnes attendues, etc.).

## 5.2 Prétraitement

L’étape de prétraitement vise à rendre les données prêtes pour l’analyse. Les principales opérations incluent :

- **Nettoyage des données** : Suppression des valeurs manquantes et des doublons afin de garantir la cohérence des données.
- **Transformation des variables** : Normalisation des données temporelles pour assurer une harmonisation des différents jeux de données.

Ces étapes ont permis de préparer un jeu de données fiable pour l’analyse et la modélisation.

## 5.3 Analyse exploratoire

Une analyse préliminaire des données a permis de dégager plusieurs tendances importantes :

- **Analyse temporelle des flux** : Identification des variations du trafic cycliste selon l’heure, le jour et le mois.
- **Cartographie du trafic** : Création de cartes interactives avec `Folium` pour visualiser les zones de forte densité de trafic.
- **Visualisation des variations de trafic** : Observation des fluctuations de la densité du trafic à travers la ville.

Cette analyse exploratoire a guidé les choix méthodologiques pour les étapes suivantes, notamment la modélisation du trafic.

## 5.4 Modélisation

Un algorithme de prédiction du trafic cycliste a été conçu en prenant en compte plusieurs variables clés :

- **Données historiques des trajets** : Utilisation des trajets passés pour identifier des tendances.
- **Localisation et fréquence des trajets** : Analyse des points de départ et d’arrivée, ainsi que des fréquences de passage.

Le modèle repose sur l’analyse des données disponibles pour estimer les flux futurs de trafic, en se basant sur les tendances observées dans les trajets passés et leur répartition géographique.

## 5.5 Visualisation

Les résultats du projet sont présentés à travers diverses visualisations interactives, permettant une exploration approfondie des données :

- **Cartes des trajets** : Visualisation des trajets réalisés par les cyclistes, avec une mise en évidence des zones de forte densité de trafic.
- **Cartes prédictives** : Représentation des trajectoires prévues pour le trafic cycliste basé sur les données historiques.
- **Carte des stations de vélos de Montpellier** : Localisation des stations de vélos en libre-service à travers la ville, permettant une meilleure compréhension des points d’accès aux vélos.
- **Visualisation vidéo** : Une vidéo illustrant l’évolution du trafic cycliste sur une journée complète, générée à partir des données du projet.

Toutes ces visualisations sont accessibles directement via le site web interactif du projet, offrant ainsi une interface intuitive pour l'exploration des flux cyclistes et des prédictions.

## 5.6 Intégration

Le pipeline a été conçu pour être flexible et évolutif afin de répondre aux besoins futurs du projet :

- **Portabilité** : Le système peut être facilement adapté à d’autres villes disposant de systèmes de vélos en libre-service similaires, permettant ainsi une application étendue de la méthodologie.
- **Scalabilité** : Le pipeline est conçu pour intégrer de nouveaux types de données, tels que celles concernant la pollution de l’air ou les conditions météorologiques, pour affiner les prédictions et les analyses.

# 6. Documentation Technique du Projet

## 6.1 Bibliothèques utilisées

Dans le cadre de ce projet, plusieurs bibliothèques ont été utilisées pour répondre aux différents besoins techniques et analytiques. Voici une présentation des bibliothèques principales et leur rôle.

<details> <summary>`csv`</summary>
La bibliothèque `csv` permet de lire et d’écrire des fichiers CSV, un format commun pour manipuler des données tabulaires.  
Nous avons utilisé `csv` pour extraire et traiter les données brutes contenues dans des fichiers au format CSV. Cela est particulièrement utile pour manipuler des ensembles de données simples où une lecture ligne par ligne est nécessaire.
</details>

<details> <summary>`matplotlib.pyplot`</summary>
`matplotlib.pyplot` est utilisée pour produire des graphiques statiques et des visualisations animées.  
Dans ce projet, elle permet de créer des graphiques dynamiques illustrant les trajectoires cyclistes et d’exporter ces visualisations sous forme de vidéos à l'aide des modules `FuncAnimation` et `FFMpegWriter`.
</details>

<details> <summary>`matplotlib.animation.FuncAnimation` et `FFMpegWriter`</summary>
Ces modules de la bibliothèque `matplotlib.animation` permettent de créer des animations et d'exporter celles-ci sous forme de fichiers vidéo.  
Dans le projet, ils sont utilisés pour générer des animations illustrant les variations temporelles du trafic cycliste et les enregistrer sous un format visuel accessible.
</details>

<details> <summary>`numpy`</summary>
`numpy` est une bibliothèque puissante pour effectuer des calculs numériques avancés, notamment des opérations matricielles.  
Les opérations matricielles et les calculs numériques complexes nécessaires à l’analyse des données sont simplifiés grâce à `numpy`, qui garantit également des performances élevées.
</details>

<details> <summary>`os`</summary>
`os` fournit des fonctions pour interagir avec le système d’exploitation, notamment pour gérer les fichiers et les répertoires.  
Nous avons utilisé `os` pour gérer les chemins des fichiers, vérifier l’existence des répertoires, et manipuler les ressources locales du système.
</details>

<details> <summary>`pooch`</summary>
`pooch` facilite le téléchargement et la mise en cache des fichiers nécessaires à l’exécution du projet.  
Cette bibliothèque permet de garantir un accès fiable aux données externes en les téléchargeant automatiquement et en les stockant localement pour une réutilisation future.
</details>

<details> <summary>`pandas`</summary>
`pandas` est essentielle pour manipuler et analyser des données tabulaires de manière efficace.  
`pandas` est utilisée pour nettoyer, transformer et analyser des ensembles de données complexes, offrant des fonctionnalités avancées comme le traitement des séries temporelles et des jointures de tables.
</details>

<details> <summary>`json`</summary>
`json` est utilisée pour manipuler des données au format JSON, un standard de stockage et d’échange d’informations structurées.  
Nous utilisons `json` pour lire et écrire des données structurées, notamment pour gérer les configurations et les résultats intermédiaires dans des fichiers légers.
</details>

<details> <summary>`re`</summary>
La bibliothèque `re` permet de travailler avec des expressions régulières pour manipuler des chaînes de caractères.  
Grâce à `re`, nous avons pu extraire des informations spécifiques des chaînes de caractères et nettoyer les données textuelles de manière efficace.
</details>

<details> <summary>`unicodedata`</summary>
`unicodedata` est utilisée pour normaliser les chaînes de caractères Unicode.  
Cette bibliothèque est essentielle pour traiter les caractères spéciaux et garantir la cohérence des chaînes de caractères provenant de différentes sources.
</details>

<details> <summary>`folium`</summary>
`folium` est une bibliothèque dédiée à la création de cartes interactives.  
Nous avons utilisé `folium` pour visualiser les trajets et itinéraires des vélos sur des cartes interactives, permettant une meilleure compréhension géographique des données.
</details>

<details> <summary>`osmnx`</summary>
`osmnx` est utilisée pour le géocodage et l’analyse des réseaux géographiques.  
Cette bibliothèque permet d’extraire des données géographiques d’OpenStreetMap, de construire des graphes routiers, et d’analyser les itinéraires et les trajets cyclistes dans le cadre de ce projet.
</details>

<details> <summary>`functools.lru_cache`</summary>
`functools.lru_cache` est une fonctionnalité de Python pour optimiser les performances.  
En mettant en cache les résultats des fonctions fréquemment appelées, `functools.lru_cache` améliore les performances et réduit le temps de calcul pour des opérations répétées.
</details>

<details> <summary>`networkx`</summary>
`networkx` est une bibliothèque dédiée à la création, la manipulation et l'analyse de graphes complexes.  
Dans ce projet, elle est utilisée pour représenter et étudier les réseaux cyclistes, notamment pour visualiser les trajets et calculer les chemins les plus courts entre les nœuds.
</details>

<details> <summary>`concurrent.futures.ThreadPoolExecutor`</summary>
`ThreadPoolExecutor` est une fonctionnalité du module standard `concurrent.futures` pour exécuter des tâches en parallèle.  
Elle est utilisée pour optimiser le traitement des données et accélérer le rendu des animations dans le cadre de ce projet.
</details>

<details> <summary>`datetime`</summary>
`datetime` est un module intégré pour manipuler les dates et les heures.  
Dans le projet, il est employé pour traiter les données temporelles des trajets cyclistes et synchroniser les animations avec les horodatages.
</details>

## 6.2 Functions utilisées

### 6.2.1 Map 

#### Fonctions de traitement des données

<details> 
  <summary>`colonne(i, w_file)`</summary>
**Description**:  
Cette fonction permet d'extraire une colonne spécifique d'un fichier CSV. Elle prend en entrée un indice `i`, représentant la colonne à extraire, ainsi que le chemin du fichier `w_file`. La fonction ouvre le fichier, parcourt chaque ligne et récupère l'élément situé à la position `i` dans chaque ligne.  

**Paramètres**:  
- `i` (int) : L'indice de la colonne à extraire.  
- `w_file` (str) : Le chemin d'accès au fichier CSV.  

**Retourne**:  
- `L` (list) : Une liste contenant les valeurs de la colonne spécifiée.  

**Code de la fonction**:  
```python
def colonne(i, w_file):
    L = []
    with open(w_file) as f:
        for line in f:
            x = line.split(",")
            L.append(x[i])
    return L
```

**Exemple d'utilisation**:  
Supposons un fichier `data.csv` contenant :  
```csv
name,age,city
Alice,30,Paris
Bob,25,Lyon
```  
Appeler `colonne(1, "data.csv")` retourne `[30, 25]`.  

[PUT ILLUSTRATION OF FUNCTION HERE]
</details>

<details> 
  <summary>`arg(k, i, j, w_file)`</summary>

**Description**:  
Cette fonction extrait les données correspondant à une clé `k` dans un fichier CSV et retourne les valeurs des colonnes spécifiées par `i` et `j`.  

**Paramètres**:  
- `k` (str) : La clé utilisée pour filtrer les données.  
- `i` (int) : L'indice de la colonne contenant les clés.  
- `j` (int) : L'indice de la colonne à retourner.  
- `w_file` (str) : Le chemin d'accès au fichier CSV.  

**Retourne**:  
- `L` (list) : Une liste contenant les valeurs correspondantes.  

**Code de la fonction**:  
```python
def arg(k, i, j, w_file):
    L = []
    with open(w_file) as f:
        for line in f:
            x = line.split(",")
            if x[i] == k:
                L.append(x[j])
    return L
```

**Exemple d'utilisation**:  
Pour le fichier `data.csv` ci-dessus, appeler `arg("Alice", 0, 2, "data.csv")` retourne `[Paris]`.  
</details>

#### Fonctions d'adresse et de géocodage

<details> 
  <summary>`nettoyer_adresse_normalise(adresse)`</summary>

**Description**:  
Nettoie et normalise une adresse en supprimant les caractères spéciaux, doublons, et autres anomalies.  

**Paramètres**:  
- `adresse` (str) : L'adresse à normaliser.  

**Retourne**:  
- `adresse` (str) : L’adresse nettoyée et normalisée.  

**Code de la fonction**:  
```python
def nettoyer_adresse_normalise(adresse):
    """
    Nettoie et normalise une adresse en supprimant les numéros au début, 
    en normalisant les caractères Unicode.
    
    Paramètre :
    adresse (str) : La chaîne d'adresse à normaliser.
    
    Retourne :
    str : L'adresse nettoyée et normalisée.
    """
    # Tenter de corriger l'encodage si nécessaire
    try:
        # Encode la chaîne en latin1 puis décode en utf-8
        adresse = adresse.encode('latin1').decode('utf-8')
    except (UnicodeEncodeError, UnicodeDecodeError):
        pass  # Ignore les erreurs d'encodage si elles se produisent

    # Supprimer les numéros ou autres formats non pertinents (ex: 057 au début)
    adresse = re.sub(r'^\d+\s*', '', adresse)  # Enlève les numéros au début
    
    # Normalisation des caractères Unicode
    adresse = unicodedata.normalize('NFKD', adresse)
    
    # Retourner l'adresse nettoyée et normalisée
    return adresse  # Enlever les espaces supplémentaires aux extrémités
```

**Exemple avant/après**:  
- Avant : `"  12, Rue de la République  "`  
- Après : `"12 rue de la république"`  

[PUT ILLUSTRATION OF CLEANED ADDRESS HERE]
</details>

<details> 
  <summary>`coordonne(station)`</summary>

<strong>Description :</strong>  
Cette fonction permet de géocoder le nom d'une station pour obtenir ses coordonnées géographiques (latitude et longitude). Elle utilise la bibliothèque `osmnx` pour rechercher l'emplacement correspondant à la station spécifiée dans la ville de Montpellier, France.

<strong>Paramètres :</strong> 
  <ul>
    <li>`station` (str) : Le nom de la station à géocoder.</li>
  </ul>

<strong>Retourne :</strong> 
  <ul>
    <li>`latitude` (float) : La latitude de la station.</li>
    <li>`longitude` (float) : La longitude de la station.</li>
  </ul>

  <strong>Code de la fonction :</strong>

  ```python
  def coordonne(station):
    try:
        # Recherche de l'emplacement en utilisant osmnx
        location = ox.geocode(f"{station}, Montpellier, France")
        return location[0], location[1]
    except Exception as e:
        print(f"Erreur pour la station {station}: {e}")
        return None, None
  ```
</details>

#### Fonctions liées à la carte

<details> 
  <summary>`gen_carte_trajet(ligne, G, m, index_colonne_départ, index_colonne_arrive, couleur)`</summary>

**Description**:  
Génère une carte interactive pour visualiser un trajet spécifique sur un graphe `G` en utilisant une bibliothèque de cartographie.  

**Paramètres**:  
  <ul>
    <li>`ligne` (list) : Une ligne contenant les noms des stations de départ et d'arrivée.</li>
    <li>`G` (Graph) : Le graphe représentant le réseau de rues de la ville.</li>
    <li>`m` (Map) : L'objet de la carte sur lequel le trajet sera tracé.</li>
    <li>`index_colonne_départ` (int) : L'indice de la colonne contenant le nom de la station de départ.</li>
    <li>`index_colonne_arrive` (int) : L'indice de la colonne contenant le nom de la station d'arrivée.</li>
    <li>`couleur` (str) : La couleur de la ligne représentant le trajet.</li>
  </ul> 

**Retourne**:  
- `map` (Map) : Une carte avec le trajet ajouté.  

**Code de la fonction**:  
```python
def gen_carte_trajet(ligne, G, m, index_colonne_départ, index_colonne_arrive,couleur):
    # Essayer de géocoder les stations de départ et d'arrivée
    try:
        origin = ox.geocode(f"{ligne[index_colonne_départ]}, Montpellier, France")  # Première colonne
        destination = ox.geocode(f"{ligne[index_colonne_arrive]}, Montpellier, France")  # Deuxième colonne
        
        # Vérifier si le géocodage a réussi
        if origin is None or destination is None:
            print(f"Erreur de géocodage pour les stations : {ligne[index_colonne_départ]} ou {ligne[index_colonne_arrive]}")
            return m
        
        # Trouver les nœuds les plus proches de l'origine et de la destination
        origin_node = ox.nearest_nodes(G, origin[1], origin[0])  # longitude, latitude
        destination_node = ox.nearest_nodes(G, destination[1], destination[0])  # longitude, latitude

        # Calculer l'itinéraire aller et retour
        route = ox.shortest_path(G, origin_node, destination_node)

        # Fonction pour convertir un itinéraire (liste de nœuds) en liste de coordonnées géographiques
        def route_to_coords(G, route):
            route_coords = []
            for node in route:
                point = (G.nodes[node]['y'], G.nodes[node]['x'])  # latitude, longitude
                route_coords.append(point)
            return route_coords

        # Obtenir les coordonnées pour l'itinéraire
        route_coords = route_to_coords(G, route)

        # Ajouter l'itinéraire aller (en rouge) à la carte
        folium.PolyLine(locations=route_coords, color=couleur, weight=5, opacity=0.75).add_to(m)

        # Ajouter des marqueurs pour l'origine et la destination
        départ_lat, départ_lon = route_coords[0]
        arr_lat, arr_lon = route_coords[-1]  # Utiliser le dernier point pour l'arrivée
        folium.Marker(location=[départ_lat, départ_lon], popup=f"{ligne[index_colonne_départ]},Départ").add_to(m)
        folium.Marker(location=[arr_lat, arr_lon], popup=f"{ligne[index_colonne_arrive]},arrivé").add_to(m)

    except Exception as e:
        print(f"Une erreur est survenue : {e}")
    
    return m
```
[PUT ILLUSTRATION OF TRAJECTORY MAP HERE]
</details>


<details>
  <summary>`map_jour(j, style)`<summary>

**Description**: 
 Génère une carte interactive pour visualiser l'intensité mesurée à chaque coordonnée sur un jour 'j'

**Paramètres**:
  <ul>
    <li>`j` (int) : Le numéro du jour de la semaine voulu (0 pour lundi, ..., 6 pour dimanche)
    <li>`style` (int): lestyle d'affichage voulu: 0 si on veut que les points des coordonnées, 1 si on veut aussi la 'chaleur'
  <\ul>

**Retourne**:
- (str) un message avec le nom de la fonction créée

**Code de la fonction**: 
```python
def map_jour(j, style):#entrée 0-6 pour les jours de la semaine, 0-1 sans-avec chaleur
    data = mean_intens(j)
    intensities = [d[0] for d in data]
    min_in = min(intensities)
    max_in = max(intensities)

    # centrer 
    ville = "Montpellier, France"
    location = ox.geocode(ville)
    m = folium.Map(location=location, zoom_start=12)


    # Ajouter les points sur la carte
    for intensity, coord in data:
        lon, lat = coord[1], coord[0]# Inversion des valeurs
        if abs(lon-location[0])<1 and abs(lat-location[1])<1:
            color = intensity_to_color(intensity, min_in, max_in)
            folium.CircleMarker(
                location=[lon, lat],
                radius=8,
                color=color,
                fill=True,
                fill_color=color,
                fill_opacity=0.6
                ).add_to(m)
        
    #choix de chaleur ou non
    if style==0:
        nom=f'intensity_{j}.html'
        m.save(nom)
        return "La carte a été générée et sauvegardée sous le nom", nom
    
    else:
        heat_data = [[coord[1], coord[0], intensity] for intensity, coord in data]
        HeatMap(heat_data).add_to(m)
        nom=f'intensity_{j}_heat.html'
        m.save(nom)
        return"La carte a été générée et sauvegardée sous le nom", nom 
```
[PUT ILLUSTRATION OF TRAJECTORY MAP HERE]
<\details>

#### Fonctions utilitaires

<details> 
  <summary>`pd_to_datetime(df, colonne_date)`</summary>

**Description**:  
Convertit une colonne d'un DataFrame Pandas en type datetime. Supprime les valeurs non valides.  

**Paramètres**:  
- `df` (DataFrame) : DataFrame Pandas.  
- `colonne_date` (str) : Nom de la colonne à convertir.  

**Retourne**:  
- `df` (DataFrame) : DataFrame avec la colonne convertie.  

  <strong>Code de la fonction :</strong>

  ```python
  def pd_to_datetime(df, colonne_date):
    df = df.dropna()
    df[colonne_date] = pd.to_datetime(df[colonne_date])
    df['Date'] = df[colonne_date].dt.date
    df = df.drop(columns=[colonne_date])
    return df
  ```
</details>

### 6.2.2 Préduction [DOCUM FROM CA - PUT HERE]

### 6.2.3 Video

<details> 
  <summary>`chemin_court(row)`</summary>

**Description**:  
Calcule le chemin le plus court entre deux stations à l'aide du graphe routier de Montpellier, basé sur leurs coordonnées géographiques.

**Paramètres**:  
- `row` (pandas.Series) : Une ligne du DataFrame contenant les coordonnées des stations de départ et d'arrivée.

**Retourne**:  
- `chemin` (list) : Une liste d'identifiants de nœuds représentant le chemin.  
- `duration` (float) : La durée du trajet en secondes.  

**Code de la fonction**:  
```python
def chemin_court(row):
    try:
        depart_lat, depart_lon = row['latitude_depart'], row['longitude_depart']
        arrivee_lat, arrivee_lon = row['latitude_retour'], row['longitude_retour']
        duration = row['Duration (sec.)']
        
        noeud_deb = ox.distance.nearest_nodes(G, depart_lon, depart_lat)
        noeud_fin = ox.distance.nearest_nodes(G, arrivee_lon, arrivee_lat)
        
        chemin = nx.shortest_path(G, noeud_deb, noeud_fin, weight="length")
        return chemin, duration
    except Exception as e:
        print(f"Erreur pour le trajet entre {row['Departure station']} et {row['Return station']}: {e}")
        return None, None
```

**Exemple d'utilisation**:  
Pour une ligne contenant les colonnes `latitude_depart`, `longitude_depart`, etc., cette fonction renvoie le chemin le plus court entre deux points.  

[PUT ILLUSTRATION OF GRAPH ROUTE HERE]
</details>

<details> 
  <summary>`init()`</summary>

**Description**:  
Initialise les points de départ pour chaque trajet dans la visualisation.  

**Retourne**:  
- `points` (list) : Une liste d'objets matplotlib représentant les points animés.  

**Code de la fonction**:  
```python
def init():
    for point in points:
        point.set_data([], [])
    time_text.set_text('')
    return points + [time_text]
```

[PUT ILLUSTRATION OF INITIALIZATION STEP HERE]
</details>

<details> 
  <summary>`update(frame)`</summary>

**Description**:  
Met à jour les positions des points dans l'animation en fonction de la progression du chemin pour chaque trajet.

**Paramètres**:  
- `frame` (int) : L'indice actuel de la frame dans l'animation.  

**Retourne**:  
- `points` (list) : Les points mis à jour pour la frame actuelle.  

**Code de la fonction**:  
```python
def update(frame):
    # Calculer l'heure actuelle
    current_time = start_time + datetime.timedelta(seconds=frame * frame_duration)
    time_text.set_text(current_time.strftime('%Y-%m-%d %H:%M:%S'))

    for i, path in enumerate(paths):
        progress = min(frame / total_frames, 1)  # Progression en fonction de total_frames
        num_nodes = int(progress * len(path))

        if num_nodes > 0:
            current_node = path[num_nodes - 1]
            x, y = G.nodes[current_node]['x'], G.nodes[current_node]['y']
            points[i].set_data([x], [y])

    return points + [time_text]
```

**Exemple d'utilisation**:  
Chaque frame de l'animation appelle cette fonction pour mettre à jour les points. La progression est calculée en fonction de `frame` et du nombre total de frames.  
</details>

## 6.3 Class

[HERE IS A TEXT ABOUT CLASS]

# 7. Testing

[tests]

# 8. Performance Analysis

[analys testing here]

# 9. User Guide



# 10. Travaux futurs

Ce projet constitue une première étape dans l'analyse du trafic cycliste à Montpellier. Plusieurs pistes peuvent être explorées pour enrichir et élargir cette étude :

- **Renforcement des modèles de prédiction** : Une amélioration des modèles actuels pourrait être réalisée en intégrant des données supplémentaires, comme les conditions météorologiques ou les événements locaux, afin d'obtenir des prévisions plus précises.

- **Ajout de données en temps réel** : L'intégration de données en temps réel, telles que les flux de trafic ou les perturbations temporaires, pourrait rendre les analyses plus dynamiques et adaptées à l'évolution des conditions.

- **Application à d'autres contextes urbains** : Étendre cette méthodologie à d'autres villes permettrait de comparer les tendances cyclistes et d'identifier des spécificités locales ou des modèles universels.

- **Amélioration de l'expérience utilisateur** : Le site Web pourrait être enrichi de fonctionnalités interactives supplémentaires, telles que la visualisation des prévisions de trafic ou des recommandations d'itinéraires alternatifs.

Ces propositions, bien qu'ambitieuses, restent accessibles et permettent d'assurer la pertinence et la durabilité du projet tout en renforçant son impact pour les usagers et les décideurs locaux.
