[
  {
    "objectID": "projet3.html",
    "href": "projet3.html",
    "title": "Visualisation vidéo",
    "section": "",
    "text": "Voici une visualisation vidéo des trajets simulés pour la journée du 2024-09-05.\n\n  Your browser does not support the video tag. \n\nVous pouvez également consulter les vidéos suivantes de notre galerie:\n1 version\n\n  Your browser does not support the video tag. \n  Your browser does not support the video tag. \n  Your browser does not support the video tag. \n  Your browser does not support the video tag. \n\nPour en savoir plus sur la méthode employée pour générer cette vidéo, consultez la section 6.2.3 Vidéo de la documentation.\n2nd version\n\n\n\n\n\nVideo Gallery\n\n\n\n\n\n\n❮\n\n  Your browser does not support the video tag. \n\n❯"
  },
  {
    "objectID": "projet1.html",
    "href": "projet1.html",
    "title": "Quelques éléments d’analyse des données",
    "section": "",
    "text": "Ci-dessous, quelques éléments d’analyse des données."
  },
  {
    "objectID": "projet1.html#nombres-totaux-de-trajets-des-différentes-années-depuis-2020.",
    "href": "projet1.html#nombres-totaux-de-trajets-des-différentes-années-depuis-2020.",
    "title": "Quelques éléments d’analyse des données",
    "section": "Nombres totaux de trajets des différentes années depuis 2020.",
    "text": "Nombres totaux de trajets des différentes années depuis 2020.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes données de la TaM n’étant pas parfaites, les données sont incomplètes."
  },
  {
    "objectID": "projet1.html#comparaison-des-trajets-journaliers-entre-les-années.",
    "href": "projet1.html#comparaison-des-trajets-journaliers-entre-les-années.",
    "title": "Quelques éléments d’analyse des données",
    "section": "Comparaison des trajets journaliers entre les années.",
    "text": "Comparaison des trajets journaliers entre les années.\n\n\n\n\n\n\n\n\n\n\n\n\nOn remarque que les différents graphes ont globalement la même forme."
  },
  {
    "objectID": "docu.html",
    "href": "docu.html",
    "title": "Documentation",
    "section": "",
    "text": "Le projet CycleVision3 a pour objectif d’analyser et de prédire les flux cyclistes dans la ville de Montpellier à l’aide de données issues de trois sources principales :\n\nVéloMagg : Historique des trajets réalisés avec le système de vélos en libre-service.\n\nCapteurs de flux cyclistes et piétons : Données collectées à partir de dispositifs installés aux points stratégiques de la ville.\n\nOpenStreetMap (OSM) : Données géographiques ouvertes, utilisées pour la cartographie et la contextualisation des trajets.\n\nL’ambition du projet est de développer des visualisations interactives, notamment une carte prédictive des flux cyclistes, accessibles via un site web dédié. Ces outils visent à :\n\nIdentifier les tendances de mobilité pour mieux comprendre les habitudes des usagers.\n\nProposer des solutions pratiques afin d’optimiser les infrastructures urbaines et de promouvoir l’usage du vélo comme moyen de transport durable.\n\nEn combinant innovation technologique et impact sociétal, CycleVision3 s’inscrit dans une démarche adaptable à d’autres contextes urbains. Ce projet contribue ainsi à la réflexion autour de la mobilité intelligente et durable, répondant aux enjeux croissants des villes contemporaines."
  },
  {
    "objectID": "docu.html#structure-du-projet-will-be-finished-at-the-end",
    "href": "docu.html#structure-du-projet-will-be-finished-at-the-end",
    "title": "Documentation",
    "section": "2.1 Structure du projet [WILL BE FINISHED AT THE END]",
    "text": "2.1 Structure du projet [WILL BE FINISHED AT THE END]\nLa structure du projet est conçue pour garantir une séparation claire des composantes essentielles à l’analyse et à la création des visualisations. Voici un aperçu de l’organisation des fichiers et répertoires :\n\n\nVoir la structure\n\nmain/                                           # Répertoire principal du projet\n├── .github/workflows/                          # Configuration pour l'intégration continue\n├── analyse_donnee/                             # Scripts pour l'analyse des données\n├── cache/                                      # Fichiers temporaires\n├── data/                                       # Données des 3 jeux de données\n│   ├── extracted/                              # Données extraites\n│   ├── CoursesVelomagg.csv                     # Données des trajets VéloMagg\n│   ├── video.csv                               # Données vidéo brutes\n│   └── video_avec_coord.csv                    # Données vidéo enrichies avec coordonnées\n├── docs/                                       # Répertoire des fichiers du site web\n│   ├── .gitignore                              # Liste des fichiers à ignorer par Git\n│   ├──                                         # \n│   ├──                                         # \n│   ├──                                         # \n│   └── styles.css                              # Fichier CSS pour la mise en forme du site\n├── images/                                     # Images utilisées dans le projet\n├── map/                                        # Scripts pour les cartes interactives\n├── roadmap/                                    # Fichier README.md avec la description .......\n├── slide/                                      # \n├── src/                                        # Répertoire contenant le code source\n│   ├── __init__.py                             # Initialisation du package\n│   ├── donnée.py                               # Fonctions de traitement des données\n│   └── fonctions_basedonnees.py                # Fonctions pour les bases de données\n├── vidéo/                                      # \n├── visualisation/                              # Résultats des visualisations\n├──.DS_Store                                    # \n├──\n├──\n├── .Rhistory                                   # Fichier d'historique R\n├── .gitignore                                  # Fichier Git ignore\n├── README.md                                   # Documentation principale du projet\n└── requirements.txt                            # Dépendances du projet"
  },
  {
    "objectID": "docu.html#installation-et-dépendances",
    "href": "docu.html#installation-et-dépendances",
    "title": "Documentation",
    "section": "2.2 Installation et dépendances",
    "text": "2.2 Installation et dépendances\nAvant de commencer le développement et l’analyse des données, il est nécessaire de configurer l’environnement de travail en installant toutes les dépendances nécessaires. Voici les étapes à suivre pour préparer le projet :\n\nÉtapes de Préparation :\n\nCloner le Dépôt Git :\nTéléchargez le projet en exécutant :\ngit clone https://github.com/mscaia/PROJ_HAX712X.git\nInstaller les Dépendances :\nInstallez les bibliothèques nécessaires :\npip install -r requirements.txt\nPrévisualiser le Site Web :\nVérifiez l’environnement en lançant le serveur Quarto :\nquarto preview"
  },
  {
    "objectID": "docu.html#configuration-des-fichiers-sphinx---cheked",
    "href": "docu.html#configuration-des-fichiers-sphinx---cheked",
    "title": "Documentation",
    "section": "2.3 Configuration des fichiers [Sphinx - CHEKED]",
    "text": "2.3 Configuration des fichiers [Sphinx - CHEKED]\nLe projet est configuré de manière à utiliser Quarto pour la création du site web interactif et [Sphinx pour la documentation générée automatiquement]. Le fichier _quarto.yml contient les paramètres de configuration du projet Quarto, tandis que le fichier index.qmd contient le contenu principal de la page d’accueil du site."
  },
  {
    "objectID": "docu.html#base-de-données-et-traitement-des-données-should-be-recheked-after",
    "href": "docu.html#base-de-données-et-traitement-des-données-should-be-recheked-after",
    "title": "Documentation",
    "section": "2.4 Base de données et traitement des données [SHOULD BE RECHEKED AFTER]",
    "text": "2.4 Base de données et traitement des données [SHOULD BE RECHEKED AFTER]\nLes principaux jeux de données sont stockés dans le répertoire data/ et comprennent :\n\nCoursesVelomagg.csv : Historique des trajets en vélos libres.\n\nvideo.csv et video_avec_coord.csv : Données vidéo pour l’analyse spatiale.\n\nLes scripts situés dans src/ effectuent :\n\nLe nettoyage des données.\n\nLa conversion des formats pour l’analyse."
  },
  {
    "objectID": "docu.html#exécution-du-projet",
    "href": "docu.html#exécution-du-projet",
    "title": "Documentation",
    "section": "2.5 Exécution du projet",
    "text": "2.5 Exécution du projet\nL’exécution du projet génère des visualisations interactives et des cartes prédictives grâce à :\n\nFolium : Création de cartes interactives.\n\nMatplotlib : Graphiques statistiques.\n\nLes résultats sont stockés dans visualisation/ et incluent des cartes des trajets et des prévisions de trafic."
  },
  {
    "objectID": "docu.html#documentation-et-tests-finish-and-rechecked",
    "href": "docu.html#documentation-et-tests-finish-and-rechecked",
    "title": "Documentation",
    "section": "2.6 Documentation et tests [FINISH AND RECHECKED]",
    "text": "2.6 Documentation et tests [FINISH AND RECHECKED]\nPour garantir la qualité du code, le projet intègre :\n\nTests Unitaires : Vérification des fonctionnalités principales.\n\nDocumentation Technique : Générée avec Sphinx et Quarto pour détailler les API, les méthodes et les résultats."
  },
  {
    "objectID": "docu.html#prétraitement-et-nettoyage-des-données",
    "href": "docu.html#prétraitement-et-nettoyage-des-données",
    "title": "Documentation",
    "section": "4.1 Prétraitement et Nettoyage des Données",
    "text": "4.1 Prétraitement et Nettoyage des Données\n\nÉtapes réalisées :\nLe nettoyage et le prétraitement des données ont constitué une étape fondamentale pour assurer la qualité et la cohérence des données utilisées dans l’analyse. Les principales actions entreprises sont les suivantes :\n\nValidation des données : Identification et traitement des anomalies, telles que les valeurs aberrantes et les doublons, avec une gestion des valeurs manquantes en fonction de leur impact sur l’analyse.\nFormatage temporel et géographique : Conversion des champs de dates pour permettre une analyse chronologique, et standardisation des adresses et coordonnées géographiques pour optimiser la géolocalisation.\n\nCette phase a permis de préparer des données propres et fiables, essentielles pour l’analyse et la création des visualisations."
  },
  {
    "objectID": "docu.html#visualisation-et-cartographie-du-trafic",
    "href": "docu.html#visualisation-et-cartographie-du-trafic",
    "title": "Documentation",
    "section": "4.2 Visualisation et Cartographie du Trafic",
    "text": "4.2 Visualisation et Cartographie du Trafic\n\nÉtapes réalisées :\nLes données traitées ont été intégrées dans des visualisations interactives et des cartes dynamiques pour illustrer le trafic cycliste à Montpellier. Les actions clés incluent :\n\nCréation de cartes interactives : Utilisation de la bibliothèque Folium pour développer une carte dynamique présentant les stations de vélos, les itinéraires fréquentés, et les zones de densité de trafic.\nCalcul des itinéraires : Emploi de la bibliothèque OSMnx pour déterminer les itinéraires entre les stations, mettant en évidence les parcours les plus utilisés et permettant l’analyse des variations temporelles du trafic.\n\nCes visualisations ont été des outils essentiels pour la compréhension des tendances du trafic cycliste, facilitant l’analyse et la prise de décisions éclairées pour les phases suivantes du projet."
  },
  {
    "objectID": "docu.html#développement-de-linterface-web",
    "href": "docu.html#développement-de-linterface-web",
    "title": "Documentation",
    "section": "4.3 Développement de l’Interface Web",
    "text": "4.3 Développement de l’Interface Web\nLe projet s’est concrétisé par la création d’un site web interactif développé avec Quarto, intégrant :\n\nLes visualisations interactives produites lors de l’analyse.\nUne carte prédictive du trafic cycliste, permettant d’estimer les flux de vélos pour le lendemain en fonction des données historiques.\n\nCette interface a été conçue pour offrir une navigation fluide et intuitive, rendant les résultats accessibles aux utilisateurs de vélos. Elle constitue un outil complet pour l’analyse des données et la planification urbaine, tout en favorisant la promotion de la mobilité durable."
  },
  {
    "objectID": "docu.html#acquisition-des-données",
    "href": "docu.html#acquisition-des-données",
    "title": "Documentation",
    "section": "5.1 Acquisition des données",
    "text": "5.1 Acquisition des données\nLes ensembles de données ont été obtenus à partir de sources officielles :\n\nDonnées VéloMagg : Historique des trajets réalisés via le système de vélos en libre-service.\nComptages cyclistes et piétons : Données de comptage obtenues par des capteurs installés à des points stratégiques de la ville.\nDonnées OpenStreetMap (OSM) : Informations géographiques utilisées pour la cartographie des trajets.\n\nLes fichiers ont été extraits sous les formats .csv et .json et chargés à l’aide de la bibliothèque pandas. Une validation initiale a été réalisée pour vérifier l’intégrité des fichiers (taille, colonnes attendues, etc.)."
  },
  {
    "objectID": "docu.html#prétraitement",
    "href": "docu.html#prétraitement",
    "title": "Documentation",
    "section": "5.2 Prétraitement",
    "text": "5.2 Prétraitement\nL’étape de prétraitement vise à rendre les données prêtes pour l’analyse. Les principales opérations incluent :\n\nNettoyage des données : Suppression des valeurs manquantes et des doublons afin de garantir la cohérence des données.\nTransformation des variables : Normalisation des données temporelles pour assurer une harmonisation des différents jeux de données.\n\nCes étapes ont permis de préparer un jeu de données fiable pour l’analyse et la modélisation."
  },
  {
    "objectID": "docu.html#analyse-exploratoire",
    "href": "docu.html#analyse-exploratoire",
    "title": "Documentation",
    "section": "5.3 Analyse exploratoire",
    "text": "5.3 Analyse exploratoire\nUne analyse préliminaire des données a permis de dégager plusieurs tendances importantes :\n\nAnalyse temporelle des flux : Identification des variations du trafic cycliste selon l’heure, le jour et le mois.\nCartographie du trafic : Création de cartes interactives avec Folium pour visualiser les zones de forte densité de trafic.\nVisualisation des variations de trafic : Observation des fluctuations de la densité du trafic à travers la ville.\n\nCette analyse exploratoire a guidé les choix méthodologiques pour les étapes suivantes, notamment la modélisation du trafic."
  },
  {
    "objectID": "docu.html#modélisation",
    "href": "docu.html#modélisation",
    "title": "Documentation",
    "section": "5.4 Modélisation",
    "text": "5.4 Modélisation\nUn algorithme de prédiction du trafic cycliste a été conçu en prenant en compte plusieurs variables clés :\n\nDonnées historiques des trajets : Utilisation des trajets passés pour identifier des tendances.\nLocalisation et fréquence des trajets : Analyse des points de départ et d’arrivée, ainsi que des fréquences de passage.\n\nLe modèle repose sur l’analyse des données disponibles pour estimer les flux futurs de trafic, en se basant sur les tendances observées dans les trajets passés et leur répartition géographique."
  },
  {
    "objectID": "docu.html#visualisation",
    "href": "docu.html#visualisation",
    "title": "Documentation",
    "section": "5.5 Visualisation",
    "text": "5.5 Visualisation\nLes résultats du projet sont présentés à travers diverses visualisations interactives, permettant une exploration approfondie des données :\n\nCartes des trajets : Visualisation des trajets réalisés par les cyclistes, avec une mise en évidence des zones de forte densité de trafic.\nCartes prédictives : Représentation des trajectoires prévues pour le trafic cycliste basé sur les données historiques.\nCarte des stations de vélos de Montpellier : Localisation des stations de vélos en libre-service à travers la ville, permettant une meilleure compréhension des points d’accès aux vélos.\nVisualisation vidéo : Une vidéo illustrant l’évolution du trafic cycliste sur une journée complète, générée à partir des données du projet.\n\nToutes ces visualisations sont accessibles directement via le site web interactif du projet, offrant ainsi une interface intuitive pour l’exploration des flux cyclistes et des prédictions."
  },
  {
    "objectID": "docu.html#intégration",
    "href": "docu.html#intégration",
    "title": "Documentation",
    "section": "5.6 Intégration",
    "text": "5.6 Intégration\nLe pipeline a été conçu pour être flexible et évolutif afin de répondre aux besoins futurs du projet :\n\nPortabilité : Le système peut être facilement adapté à d’autres villes disposant de systèmes de vélos en libre-service similaires, permettant ainsi une application étendue de la méthodologie.\nScalabilité : Le pipeline est conçu pour intégrer de nouveaux types de données, tels que celles concernant la pollution de l’air ou les conditions météorologiques, pour affiner les prédictions et les analyses."
  },
  {
    "objectID": "docu.html#bibliothèques-utilisées",
    "href": "docu.html#bibliothèques-utilisées",
    "title": "Documentation",
    "section": "6.1 Bibliothèques utilisées",
    "text": "6.1 Bibliothèques utilisées\nDans le cadre de ce projet, plusieurs bibliothèques ont été utilisées pour répondre aux différents besoins techniques et analytiques. Voici une présentation des bibliothèques principales et leur rôle.\n\n\nconcurrent.futures.ThreadPoolExecutor\n\nThreadPoolExecutor est une fonctionnalité du module standard concurrent.futures pour exécuter des tâches en parallèle.\nElle est utilisée pour optimiser le traitement des données et accélérer le rendu des animations dans le cadre de ce projet.\n\n\n\ncsv\n\nLa bibliothèque csv permet de lire et d’écrire des fichiers CSV, un format commun pour manipuler des données tabulaires.\nNous avons utilisé csv pour extraire et traiter les données brutes contenues dans des fichiers au format CSV. Cela est particulièrement utile pour manipuler des ensembles de données simples où une lecture ligne par ligne est nécessaire.\n\n\n\ndatetime\n\ndatetime est un module intégré pour manipuler les dates et les heures.\nDans le projet, il est employé pour traiter les données temporelles des trajets cyclistes et synchroniser les animations avec les horodatages.\n\n\n\nfolium\n\nfolium est une bibliothèque dédiée à la création de cartes interactives.\nNous avons utilisé folium pour visualiser les trajets et itinéraires des vélos sur des cartes interactives, permettant une meilleure compréhension géographique des données.\n\n\n\nfunctools.lru_cache\n\nfunctools.lru_cache est une fonctionnalité de Python pour optimiser les performances.\nEn mettant en cache les résultats des fonctions fréquemment appelées, functools.lru_cache améliore les performances et réduit le temps de calcul pour des opérations répétées.\n\n\n\njson\n\njson est utilisée pour manipuler des données au format JSON, un standard de stockage et d’échange d’informations structurées.\nNous utilisons json pour lire et écrire des données structurées, notamment pour gérer les configurations et les résultats intermédiaires dans des fichiers légers.\n\n\n\nmatplotlib.animation.FuncAnimation et FFMpegWriter\n\nCes modules de la bibliothèque matplotlib.animation permettent de créer des animations et d’exporter celles-ci sous forme de fichiers vidéo.\nDans le projet, ils sont utilisés pour générer des animations illustrant les variations temporelles du trafic cycliste et les enregistrer sous un format visuel accessible.\n\n\n\nmatplotlib.pyplot\n\nmatplotlib.pyplot est utilisée pour produire des graphiques statiques et des visualisations animées.\nDans ce projet, elle permet de créer des graphiques dynamiques illustrant les trajectoires cyclistes et d’exporter ces visualisations sous forme de vidéos à l’aide des modules FuncAnimation et FFMpegWriter.\n\n\n\nnetworkx\n\nnetworkx est une bibliothèque dédiée à la création, la manipulation et l’analyse de graphes complexes.\nDans ce projet, elle est utilisée pour représenter et étudier les réseaux cyclistes, notamment pour visualiser les trajets et calculer les chemins les plus courts entre les nœuds.\n\n\n\nnumpy\n\nnumpy est une bibliothèque puissante pour effectuer des calculs numériques avancés, notamment des opérations matricielles.\nLes opérations matricielles et les calculs numériques complexes nécessaires à l’analyse des données sont simplifiés grâce à numpy, qui garantit également des performances élevées.\n\n\n\nos\n\nos fournit des fonctions pour interagir avec le système d’exploitation, notamment pour gérer les fichiers et les répertoires.\nNous avons utilisé os pour gérer les chemins des fichiers, vérifier l’existence des répertoires, et manipuler les ressources locales du système.\n\n\n\nosmnx\n\nosmnx est utilisée pour le géocodage et l’analyse des réseaux géographiques.\nCette bibliothèque permet d’extraire des données géographiques d’OpenStreetMap, de construire des graphes routiers, et d’analyser les itinéraires et les trajets cyclistes dans le cadre de ce projet.\n\n\n\npandas\n\npandas est essentielle pour manipuler et analyser des données tabulaires de manière efficace.\npandas est utilisée pour nettoyer, transformer et analyser des ensembles de données complexes, offrant des fonctionnalités avancées comme le traitement des séries temporelles et des jointures de tables.\n\n\n\npooch\n\npooch facilite le téléchargement et la mise en cache des fichiers nécessaires à l’exécution du projet.\nCette bibliothèque permet de garantir un accès fiable aux données externes en les téléchargeant automatiquement et en les stockant localement pour une réutilisation future.\n\n\n\nre\n\nLa bibliothèque re permet de travailler avec des expressions régulières pour manipuler des chaînes de caractères.\nGrâce à re, nous avons pu extraire des informations spécifiques des chaînes de caractères et nettoyer les données textuelles de manière efficace.\n\n\n\nunicodedata\n\nunicodedata est utilisée pour normaliser les chaînes de caractères Unicode.\nCette bibliothèque est essentielle pour traiter les caractères spéciaux et garantir la cohérence des chaînes de caractères provenant de différentes sources.\n\n\n\nzipfile\n\nLa bibliothèque zipfile permet de travailler avec des fichiers au format ZIP, un format couramment utilisé pour la compression et l’archivage de fichiers.\nNous avons utilisé zipfile pour extraire des fichiers compressés afin de récupérer les données nécessaires à notre projet. Cette bibliothèque offre une interface simple pour l’extraction, la création et la gestion des archives ZIP, ce qui facilite le traitement des données compressées."
  },
  {
    "objectID": "docu.html#fonctions-utilisées",
    "href": "docu.html#fonctions-utilisées",
    "title": "Documentation",
    "section": "6.2 Fonctions utilisées",
    "text": "6.2 Fonctions utilisées\n\n6.2.1 Map\n\nFonctions de traitement des données\n\n\ncolonne(i, w_file)\n\nDescription:\nCette fonction permet d’extraire une colonne spécifique d’un fichier CSV. Elle prend en entrée un indice i, représentant la colonne à extraire, ainsi que le chemin du fichier w_file. La fonction ouvre le fichier, parcourt chaque ligne et récupère l’élément situé à la position i dans chaque ligne.\nParamètres:\n- i (int) : L’indice de la colonne à extraire.\n- w_file (str) : Le chemin d’accès au fichier CSV.\nRetourne:\n- L (list) : Une liste contenant les valeurs de la colonne spécifiée.\nCode de la fonction:\ndef colonne(i, w_file):\n    L = []\n    with open(w_file) as f:\n        for line in f:\n            x = line.split(\",\")\n            L.append(x[i])\n    return L\nExemple d’utilisation:\nSupposons un fichier data.csv contenant :\nname,age,city\nAlice,30,Paris\nBob,25,Lyon\nAppeler colonne(1, \"data.csv\") retourne [30, 25].\n[PUT ILLUSTRATION OF FUNCTION HERE]\n\n\n\narg(k, i, j, w_file)\n\nDescription:\nCette fonction extrait les données correspondant à une clé k dans un fichier CSV et retourne les valeurs des colonnes spécifiées par i et j.\nParamètres:\n- k (str) : La clé utilisée pour filtrer les données.\n- i (int) : L’indice de la colonne contenant les clés.\n- j (int) : L’indice de la colonne à retourner.\n- w_file (str) : Le chemin d’accès au fichier CSV.\nRetourne:\n- L (list) : Une liste contenant les valeurs correspondantes.\nCode de la fonction:\ndef arg(k, i, j, w_file):\n    L = []\n    with open(w_file) as f:\n        for line in f:\n            x = line.split(\",\")\n            if x[i] == k:\n                L.append(x[j])\n    return L\nExemple d’utilisation:\nPour le fichier data.csv ci-dessus, appeler arg(\"Alice\", 0, 2, \"data.csv\") retourne [Paris].\n\n\n\nFonctions d’adresse et de géocodage\n\n\nnettoyer_adresse_normalise(adresse)\n\nDescription:\nNettoie et normalise une adresse en supprimant les caractères spéciaux, doublons, et autres anomalies.\nParamètres:\n- adresse (str) : L’adresse à normaliser.\nRetourne:\n- adresse (str) : L’adresse nettoyée et normalisée.\nCode de la fonction:\ndef nettoyer_adresse_normalise(adresse):\n    \"\"\"\n    Nettoie et normalise une adresse en supprimant les numéros au début, \n    en normalisant les caractères Unicode.\n    \n    Paramètre :\n    adresse (str) : La chaîne d'adresse à normaliser.\n    \n    Retourne :\n    str : L'adresse nettoyée et normalisée.\n    \"\"\"\n    # Tenter de corriger l'encodage si nécessaire\n    try:\n        # Encode la chaîne en latin1 puis décode en utf-8\n        adresse = adresse.encode('latin1').decode('utf-8')\n    except (UnicodeEncodeError, UnicodeDecodeError):\n        pass  # Ignore les erreurs d'encodage si elles se produisent\n\n    # Supprimer les numéros ou autres formats non pertinents (ex: 057 au début)\n    adresse = re.sub(r'^\\d+\\s*', '', adresse)  # Enlève les numéros au début\n    \n    # Normalisation des caractères Unicode\n    adresse = unicodedata.normalize('NFKD', adresse)\n    \n    # Retourner l'adresse nettoyée et normalisée\n    return adresse  # Enlever les espaces supplémentaires aux extrémités\nExemple avant/après:\n- Avant : \"  12, Rue de la République  \"\n- Après : \"12 rue de la république\"\n[PUT ILLUSTRATION OF CLEANED ADDRESS HERE]\n\n\n\ncoordonne(station)\n\nDescription :\nCette fonction permet de géocoder le nom d’une station pour obtenir ses coordonnées géographiques (latitude et longitude). Elle utilise la bibliothèque osmnx pour rechercher l’emplacement correspondant à la station spécifiée dans la ville de Montpellier, France.\nParamètres :\n\n\nstation (str) : Le nom de la station à géocoder.\n\n\nRetourne :\n\n\nlatitude (float) : La latitude de la station.\n\n\nlongitude (float) : La longitude de la station.\n\n\nCode de la fonction :\n  def coordonne(station):\n    try:\n        # Recherche de l'emplacement en utilisant osmnx\n        location = ox.geocode(f\"{station}, Montpellier, France\")\n        return location[0], location[1]\n    except Exception as e:\n        print(f\"Erreur pour la station {station}: {e}\")\n        return None, None\n\n\n\nFonctions liées à la carte\n\n\ngen_carte_trajet(ligne, G, m, index_colonne_départ, index_colonne_arrive, couleur)\n\nDescription:\nGénère une carte interactive pour visualiser un trajet spécifique sur un graphe G en utilisant une bibliothèque de cartographie.\nParamètres:\n\n\n\nligne (list) : Une ligne contenant les noms des stations de départ et d’arrivée.\n\n\nG (Graph) : Le graphe représentant le réseau de rues de la ville.\n\n\nm (Map) : L’objet de la carte sur lequel le trajet sera tracé.\n\n\nindex_colonne_départ (int) : L’indice de la colonne contenant le nom de la station de départ.\n\n\nindex_colonne_arrive (int) : L’indice de la colonne contenant le nom de la station d’arrivée.\n\n\ncouleur (str) : La couleur de la ligne représentant le trajet.\n\n\nRetourne:\n- map (Map) : Une carte avec le trajet ajouté.\nCode de la fonction:\ndef gen_carte_trajet(ligne, G, m, index_colonne_départ, index_colonne_arrive,couleur):\n    # Essayer de géocoder les stations de départ et d'arrivée\n    try:\n        origin = ox.geocode(f\"{ligne[index_colonne_départ]}, Montpellier, France\")  # Première colonne\n        destination = ox.geocode(f\"{ligne[index_colonne_arrive]}, Montpellier, France\")  # Deuxième colonne\n        \n        # Vérifier si le géocodage a réussi\n        if origin is None or destination is None:\n            print(f\"Erreur de géocodage pour les stations : {ligne[index_colonne_départ]} ou {ligne[index_colonne_arrive]}\")\n            return m\n        \n        # Trouver les nœuds les plus proches de l'origine et de la destination\n        origin_node = ox.nearest_nodes(G, origin[1], origin[0])  # longitude, latitude\n        destination_node = ox.nearest_nodes(G, destination[1], destination[0])  # longitude, latitude\n\n        # Calculer l'itinéraire aller et retour\n        route = ox.shortest_path(G, origin_node, destination_node)\n\n        # Fonction pour convertir un itinéraire (liste de nœuds) en liste de coordonnées géographiques\n        def route_to_coords(G, route):\n            route_coords = []\n            for node in route:\n                point = (G.nodes[node]['y'], G.nodes[node]['x'])  # latitude, longitude\n                route_coords.append(point)\n            return route_coords\n\n        # Obtenir les coordonnées pour l'itinéraire\n        route_coords = route_to_coords(G, route)\n\n        # Ajouter l'itinéraire aller (en rouge) à la carte\n        folium.PolyLine(locations=route_coords, color=couleur, weight=5, opacity=0.75).add_to(m)\n\n        # Ajouter des marqueurs pour l'origine et la destination\n        départ_lat, départ_lon = route_coords[0]\n        arr_lat, arr_lon = route_coords[-1]  # Utiliser le dernier point pour l'arrivée\n        folium.Marker(location=[départ_lat, départ_lon], popup=f\"{ligne[index_colonne_départ]},Départ\").add_to(m)\n        folium.Marker(location=[arr_lat, arr_lon], popup=f\"{ligne[index_colonne_arrive]},arrivé\").add_to(m)\n\n    except Exception as e:\n        print(f\"Une erreur est survenue : {e}\")\n    \n    return m\n[PUT ILLUSTRATION OF TRAJECTORY MAP HERE]\n\n\n\nmap_jour(j, style)\n\nDescription: Génère une carte interactive pour visualiser l’intensité mesurée à chaque coordonnée sur un jour ‘j’\nParamètres:\n\n\nj (int) : Le numéro du jour de la semaine voulu (0 pour lundi, …, 6 pour dimanche)\n\nstyle (int): lestyle d’affichage voulu: 0 si on veut que les points des coordonnées, 1 si on veut aussi la ‘chaleur’ &lt;\nRetourne: - (str) un message avec le nom de la fonction créée\nCode de la fonction:\ndef map_jour(j, style):#entrée 0-6 pour les jours de la semaine, 0-1 sans-avec chaleur\n    data = mean_intens(j)\n    intensities = [d[0] for d in data]\n    min_in = min(intensities)\n    max_in = max(intensities)\n\n    # centrer \n    ville = \"Montpellier, France\"\n    location = ox.geocode(ville)\n    m = folium.Map(location=location, zoom_start=12)\n\n\n    # Ajouter les points sur la carte\n    for intensity, coord in data:\n        lon, lat = coord[1], coord[0]# Inversion des valeurs\n        if abs(lon-location[0])&lt;1 and abs(lat-location[1])&lt;1:\n            color = intensity_to_color(intensity, min_in, max_in)\n            folium.CircleMarker(\n                location=[lon, lat],\n                radius=8,\n                color=color,\n                fill=True,\n                fill_color=color,\n                fill_opacity=0.6\n                ).add_to(m)\n        \n    #choix de chaleur ou non\n    if style==0:\n        nom=f'intensity_{j}.html'\n        m.save(nom)\n        return \"La carte a été générée et sauvegardée sous le nom\", nom\n    \n    else:\n        heat_data = [[coord[1], coord[0], intensity] for intensity, coord in data]\n        HeatMap(heat_data).add_to(m)\n        nom=f'intensity_{j}_heat.html'\n        m.save(nom)\n        return\"La carte a été générée et sauvegardée sous le nom\", nom \n[PUT ILLUSTRATION OF TRAJECTORY MAP HERE]\n\n\n\nmap_trajets(j, h)\n\nDescription: Génère une carte représentant tout les trajets moyens empruntés le jour j à l’heure h représentés par couleur en fonction de l’intensité.\nParamètres:\n\n\nj (int) : Le numéro du jour de la semaine voulu (0 pour lundi, …, 6 pour dimanche)\n\nh (int): Le numéro de l’heure dans la journée qu’on veut observer (de 0 à 23) &lt;\nRetourne: - (list, str): une liste des stations de départ et d’arrivée de tous les trajets qui n’ont pas été tracés et un message avec le nom de la fonction créée\nCode de la fonction:\ndef map_trajets(j, h):\n    trajets=trajets_parcourus(j, h)\n    stations_dict = {station[0]: station[1] for station in stations}\n    N=nb_tot_jour(j)\n    \n    \n    ville = \"Montpellier, France\"\n    location = ox.geocode(ville)\n\n    # marge de distances supplémentaire\n    graphe = ox.graph_from_point(location, dist=10000, network_type=\"bike\", simplify=True)\n\n    # Initialisation\n    carte = folium.Map(location=location, zoom_start=13)\n\n    #nb passages \n    edges_passages = defaultdict(int)\n\n    for trajet in trajets:\n        try:\n            start, end = trajet[0]\n            intensity = trajet[1]/N\n            if start in stations_dict and end in stations_dict:\n                lon_start, lat_start = stations_dict[start]\n                lon_end, lat_end = stations_dict[end]\n\n                # Trouver les nœuds les plus proches dans le graphe\n                try:\n                    start_node = ox.distance.nearest_nodes(graphe, lon_start, lat_start)\n                    end_node = ox.distance.nearest_nodes(graphe, lon_end, lat_end)\n\n                    # Calculer le chemin entre les deux nœuds\n                    path = nx.shortest_path(graphe, start_node, end_node, weight=\"length\")\n\n                    # Ajouter chaque segment du chemin au compteur de passages\n                    for u, v in zip(path[:-1], path[1:]):\n                        edges_passages[(u, v)] += intensity\n                        edges_passages[(v, u)] += intensity  #on compte les passages dans les deux sens \n                except nx.NetworkXNoPath:\n                    print(f\"Aucun chemin entre {start} et {end}\")\n        except Exception as e:\n            print(f\"Erreur lors du traitement du trajet {trajet}: {e}\")\n\n    #couleurs en fonction du nb de passages\n    for (u, v), passage_count in edges_passages.items():\n        # récup coordonnées des segments\n        coords = [\n            (graphe.nodes[u]['y'], graphe.nodes[u]['x']),\n            (graphe.nodes[v]['y'], graphe.nodes[v]['x'])\n        ]\n\n        # Calcul de la couleur\n        if passage_count &lt; 0.5:\n           color= \"#0000ff\" \n        else:     \n            max_intensity = 4  # Ajuster selon les données\n            passage_clamped = max(0, min(passage_count, max_intensity))  # Limiter à une plage raisonnable\n            red = int(255 * (passage_clamped / max_intensity))\n            green = int(255 * (1 - passage_clamped / max_intensity))\n            color = f\"#{red:02x}{green:02x}00\"\n\n\n        # Ajouter chaque segment\n        folium.PolyLine(\n            locations=coords,\n            color=color,\n            weight=4,  # Épaisseur fixe\n            opacity=0.8,\n            tooltip=f\"Passages: {passage_count}\"\n        ).add_to(carte)\n\n    # Ajout des stations comme marqueurs\n    for station in stations:\n        try:\n            (lon, lat) = station[1]\n            for k in name_sta: \n                if k[0]==station[0]: \n                    name= k[1]\n            folium.Marker(\n                location=(lat, lon),\n                popup=f\"{name}: {lon}, {lat}\",\n                icon=folium.Icon(color=\"gray\")\n            ).add_to(carte)\n        except Exception as e:\n            print(f\"Erreur lors de l'ajout de la station {station}: {e}\")\n\n    # légende \n    legend_html = \"\"\"\n    &lt;div style=\"\n        position: fixed;\n        bottom: 50px;\n        left: 50px;\n        width: 200px;\n        height: 140px;\n        background-color: white;\n        border:2px solid grey;\n        z-index:9999;\n        font-size:14px;\n        padding: 10px;\n        \"&gt;\n        &lt;b&gt;Nombre de passages:&lt;/b&gt;&lt;br&gt;\n        &lt;i style=\"background: #0000ff; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Très faible (&lt;1)&lt;br&gt;\n        &lt;i style=\"background: #00ff00; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Faible (1-2)&lt;br&gt;\n        &lt;i style=\"background: #80ff00; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Modérée (3-5)&lt;br&gt;\n        &lt;i style=\"background: #ff0000; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Forte (&gt;5)&lt;br&gt;\n    &lt;/div&gt;\n    \"\"\"\n    carte.get_root().html.add_child(folium.Element(legend_html))\n\n    # Save la carte\n    nom = f\"trajets_couleurs_cumulées_j{j}_h{h}.html\"\n    carte.save(nom)\n    return f\"Carte enregistrée sous '{nom}'.\"\n[PUT ILLUSTRATION OF TRAJECTORY MAP HERE]\n\n\n\nFonctions utilitaires\n\n\npd_to_datetime(df, colonne_date)\n\nDescription:\nConvertit une colonne d’un DataFrame Pandas en type datetime. Supprime les valeurs non valides.\nParamètres:\n- df (DataFrame) : DataFrame Pandas.\n- colonne_date (str) : Nom de la colonne à convertir.\nRetourne:\n- df (DataFrame) : DataFrame avec la colonne convertie.\nCode de la fonction :\n  def pd_to_datetime(df, colonne_date):\n    df = df.dropna()\n    df[colonne_date] = pd.to_datetime(df[colonne_date])\n    df['Date'] = df[colonne_date].dt.date\n    df = df.drop(columns=[colonne_date])\n    return df\n\n\n\njour_semaine(j)\n\nDescription: Crée une liste des données uniquement pour les jours correspondant au jour j\nParamètres:\n\n\nj (int) : Le numéro du jour de la semaine voulu (0 pour lundi, …, 6 pour dimanche) &lt;\nRetourne: - (list): une liste des données prises un jour j\nCode de la fonction:\ndef jour_semaine(j):\n    Lundi=[]\n    Mardi=[]\n    Mercredi=[]\n    Jeudi=[]\n    Vendredi=[]\n    Samedi=[]\n    Dimanche=[]\n    for i in range (len(donnees_utiles)): \n        date=datetime.strptime(donnees_utiles[i][1], '%Y-%m-%d')\n        jour=date.weekday()\n        if jour==0:\n            Lundi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==1:\n            Mardi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==2:\n            Mercredi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==3:\n            Jeudi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==4:\n            Vendredi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==5:\n            Samedi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        else:\n            Dimanche.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n    if j==0:\n        return Lundi\n    elif j==1:\n        return Mardi \n    elif j==2:\n        return Mercredi \n    elif j==3:\n        return Jeudi\n    elif j==4:\n        return Vendredi \n    elif j==5:\n        return Samedi \n    else:\n        return Dimanche \n\n\n\ncoor_unique(j)\n\nDescription: Crée une liste des coordonnées de façon unique pour les jours correspondant au jour j\nParamètres:\n\n\nj (int) : Le numéro du jour de la semaine voulu (0 pour lundi, …, 6 pour dimanche) &lt;\nRetourne: - (list): une liste des coordonnées actives sur un jour j\nCode de la fonction:\ndef coor_unique(j):\n    L=jour_semaine(j)\n    co=[]\n    for i in L:\n        if i[1] not in co:\n            co.append(i[1])\n    return co\n\n\n\nnb_tot_jour(j)\n\nDescription: Compte le nombre de jours correspondant au jour j\nParamètres:\n\n\nj (int) : Le numéro du jour de la semaine voulu (0 pour lundi, …, 6 pour dimanche) &lt;\nRetourne: -len(D) (int): le nombre de jours étant un jour j dans les données\nCode de la fonction:\ndef nb_tot_jour(j):\n    D=[]\n    for file in files:\n        with open(file, 'r', encoding='utf-8') as f:\n            lecteur = csv.reader(f, delimiter=';')  # Séparateur ';' dans les 'files'\n            next(lecteur) #ignorer l'entête \n            for ligne in lecteur: \n                dat, heur = ligne[0].split(' ')\n                date=datetime.strptime(dat, '%Y-%m-%d')\n                jour=date.weekday()\n                if jour==j:\n                    dep=ligne[2].split(' ')[0]\n                    arr=ligne[3].split(' ')[0]\n                    if dep!='' and arr!='':\n                        if dep in Sta and arr in Sta:\n                            if dat not in D:\n                                D.append(dat)\n    return len(D)\n\n\n\n\n6.2.2 Prédiction\n\n\nmean_intens(j)\n\nDescription: Cette fonction donne l’intensité moyenne par coordonnée mesurée sur un jour j.\nParamètre:\n\n\nj (int): Le numéro du jour de la semaine (0 pour lundi, …, 6 pour dimanche)\n\nRetourne: - M (matrix): Une matrice contenant les valeurs des intensités pour chaque coordonnée sur le jour j en moyenne.\nCode de la fonction:\ndef mean_intens(j):\n    N=0 \n    L=jour_semaine(j)\n    M=[]\n    for i in L: \n        N=0 \n        sum=i[0]\n        n=0 \n        k=0 \n        for h in L:\n            if h[1]==i[1]:\n                sum+=h[0]\n                N+=1 \n        if len(M)&gt;0:\n            while n==0 and k&lt;len(M):\n                if i[1]==M[k][1]:\n                    n=1\n                k+=1\n        if n==0:\n            i[0]=sum/N\n            M.append(i)\n    return M \nExemple d’utilisation: Supposons que les données soient:\ncoordinate, date, intensity\n[3.48, 43.8], 2022-03-12, 26\n[3.47, 43.7], 2022-03-19, 32\n[3.48, 43.8], 2202-03-19, 15\nComme le 12 et le 19 mars 2022 sont des samedis: Appeler mean_intens(5) retourne [[[3.48, 43.8], 20.5], [[3.47, 43.7], 32]]\n\n\n\nintensity_to_color(intens, min_in, max_in):\n\nDescription: Cette fonction associe une couleur à une intensité en fonction de sa “position” par rapport aux intensités maximales et minimales\nParamètre:\n\n\nintens (int): Valeur de l’intensité qu’on cherche à associer à une couleur\n\nmin_int (int): Valeur de l’intensité minimale\n\nmax_int (int): Valeur de l’intensité maximale\n\nRetourne: - rgba(x, y, z, 1) (list): Une liste contenant le code couleur associé à l’intensité représentée\nCode de la fonction:\ndef intensity_to_color(intens, min_in, max_in):  \n    norm_in = (intens - min_in) / (max_in - min_in)\n    color = plt.cm.RdYlGn_r(norm_in)  # Colormap GnYlRd(vert à rouge)\n    return 'rgba({}, {}, {}, {})'.format(int(color[0] * 255), int(color[1] * 255), int(color[2] * 255), 1)\nExemple d’utilisation: Suppososns qu’on veuille représenter la valeur 12 sur une échelle allant de 6 à 18\nAppeler intensity_to_color(12, 6, 18) retourne rgba(254, 254, 189, 1)\n\n\n\npoids_par_heure(j):\n\nDescription: Cette fonction classe les trajets d’un jour j par heure\nParamètre: - j (int): Numéro du jour de la semaine (0 pour lundi, …, 6 pour dimanche)\nRetourne: -pourcentage de trajets par heure M avec M (matrix): [[station départ, station arrivée], nombre de trajets *100/nombre total de trajets sur j]\nCode de la fonction:\ndef poids_par_h(j):\n    heures = {heure: 0 for heure in range(24)}\n    D=[]\n    for file in files:\n        with open(file, 'r', encoding='utf-8') as f:\n            lecteur = csv.reader(f, delimiter=';')  \n            next(lecteur) #ignorer l'entête \n            for ligne in lecteur: \n                dat, heur = ligne[0].split(' ')\n                date=datetime.strptime(dat, '%Y-%m-%d')\n                jour=date.weekday()\n                if jour==j:\n                    dep=ligne[2].split(' ')[0]\n                    arr=ligne[3].split(' ')[0]\n                    if dep!='' and arr!='':\n                        if dep in Sta and arr in Sta:\n                            if dat not in D:\n                                D.append(dat)\n                            heure = int(heur.split(':')[0])  # Extraire l'heure\n                            heures[heure] += 1 # Incrémenter le compteur pour cette heure\n    N=len(D)\n    H=[heures[h]/N for h in heures]\n    t=sum(H[h] for h in heures)\n    return 'pourcentage de trajets par heure', [[h, H[h]*100/t] for h in heures]\nExemple d’utilisation: Supposons qu’il y ait 750 trajets un jeudi dont 300 entre midi et 13h, 200 entre 18h et 19h et 250 entre 8h et 9h\nAppeler poids_par_heure retourne [[0, 0],[1, 0],[2, 0],[3, 0],[4, 0],[5, 0], [6, 0],[7, 0], [8, 33.33], [9, 0],[10, 0],[11, 0],[12, 40],[13, 0],[14, 0],[15, 0],[16, 0],[17, 0],[18, 26.66],[19, 0],[20, 0],[21, 0],[22, 0],[23, 0]]\n\n\n\ntrajets_parcourus(j, h):\n\nDescription: Cette fonction classe les trajets d’un jour j à une heure h avec leur multiplicité moyenne.\nParamètre:\n\n\nj (int): Numéro du jour de la semaine (0 pour lundi, …, 6 pour dimanche)\n\nh (int): Numéro de l’heure dans la journée (0 pour 00:00-00:59, …, 23 pour 23:00-23:59]\n\nRetourne: -F (matrix): [[station départ, station arrivée], multiplicité à l’heure h dans le jour j]\nCode de la fonction:\ndef trajets_parcourus(j,h):\n    D=[]\n    T=[]\n    U=[]\n    F=[]\n    for file in files:\n        with open(file, 'r', encoding='utf-8') as f:\n            lecteur = csv.reader(f, delimiter=';')  # Définir le séparateur si nécessaire\n            next(lecteur) #ignorer l'entête \n            for ligne in lecteur: \n                dat, heur = ligne[0].split(' ')\n                dep=ligne[2].split(' ')[0]\n                arr=ligne[3].split(' ')[0]\n                date=datetime.strptime(dat, '%Y-%m-%d')\n                jour=date.weekday()\n                if jour==j:\n                    if dep!='' and arr!='':\n                        if dep in Sta and arr in Sta:\n                            D.append([heur, dep, arr])\n    #return D #récupération de tous les trajets pour les jours j\n    for j in D:\n        H=int(j[0].split(':')[0])\n        if H==h:\n            T.append([j[1],j[2]])\n    #return T #récupérations de tous les trajets pour les jours j à l'heure h\n    for I in T:\n        if I not in U:\n            U.append(I) \n    #return U #récupération de tous les trajets de façon unique\n    for s in U:\n        c=0\n        for t in T:\n            if t==s:\n                c+=1\n        F.append([s,c])\n    return F\nExemple d’utilisation: Supposons qu’il y ait 25 trajets un jeudi entre midi et 13h faisant Comédie-Fac des sciences Appeler trajets_parcourus(3, 12) retourne une matrice dont l’une des lignes est [['Comédie', 'Fac des sciences'], 25]\n\n\n\n6.2.3 Video\n\n\nchemin_court(row)\n\nDescription:\nCalcule le chemin le plus court entre deux stations à l’aide du graphe routier de Montpellier, basé sur leurs coordonnées géographiques.\nParamètres:\n- row (pandas.Series) : Une ligne du DataFrame contenant les coordonnées des stations de départ et d’arrivée.\nRetourne:\n- chemin (list) : Une liste d’identifiants de nœuds représentant le chemin.\n- duration (float) : La durée du trajet en secondes.\nCode de la fonction:\ndef chemin_court(row):\n    try:\n        depart_lat, depart_lon = row['latitude_depart'], row['longitude_depart']\n        arrivee_lat, arrivee_lon = row['latitude_retour'], row['longitude_retour']\n        duration = row['Duration (sec.)']\n        \n        noeud_deb = ox.distance.nearest_nodes(G, depart_lon, depart_lat)\n        noeud_fin = ox.distance.nearest_nodes(G, arrivee_lon, arrivee_lat)\n        \n        chemin = nx.shortest_path(G, noeud_deb, noeud_fin, weight=\"length\")\n        return chemin, duration\n    except Exception as e:\n        print(f\"Erreur pour le trajet entre {row['Departure station']} et {row['Return station']}: {e}\")\n        return None, None\nExemple d’utilisation:\nPour une ligne contenant les colonnes latitude_depart, longitude_depart, etc., cette fonction renvoie le chemin le plus court entre deux points.\n[PUT ILLUSTRATION OF GRAPH ROUTE HERE]\n\n\n\ninit()\n\nDescription:\nInitialise les points de départ pour chaque trajet dans la visualisation.\nRetourne:\n- points (list) : Une liste d’objets matplotlib représentant les points animés.\nCode de la fonction:\ndef init():\n    for point in points:\n        point.set_data([], [])\n    time_text.set_text('')\n    return points + [time_text]\n[PUT ILLUSTRATION OF INITIALIZATION STEP HERE]\n\n\n\nupdate(frame)\n\nDescription:\nMet à jour les positions des points dans l’animation en fonction de la progression du chemin pour chaque trajet.\nParamètres:\n- frame (int) : L’indice actuel de la frame dans l’animation.\nRetourne:\n- points (list) : Les points mis à jour pour la frame actuelle.\nCode de la fonction:\ndef update(frame):\n    # Calculer l'heure actuelle\n    current_time = start_time + datetime.timedelta(seconds=frame * frame_duration)\n    time_text.set_text(current_time.strftime('%Y-%m-%d %H:%M:%S'))\n\n    for i, path in enumerate(paths):\n        progress = min(frame / total_frames, 1)  # Progression en fonction de total_frames\n        num_nodes = int(progress * len(path))\n\n        if num_nodes &gt; 0:\n            current_node = path[num_nodes - 1]\n            x, y = G.nodes[current_node]['x'], G.nodes[current_node]['y']\n            points[i].set_data([x], [y])\n\n    return points\nExemple d’utilisation:\nChaque frame de l’animation appelle cette fonction pour mettre à jour les points. La progression est calculée en fonction de frame et du nombre total de frames."
  },
  {
    "objectID": "docu.html#class-gestionnairedonnees",
    "href": "docu.html#class-gestionnairedonnees",
    "title": "Documentation",
    "section": "6.3 Class “GestionnaireDonnees”",
    "text": "6.3 Class “GestionnaireDonnees”\nLa classe GestionnaireDonnees a été créée pour gérer le téléchargement, la lecture et le traitement des jeux de données. Elle centralise les fonctions nécessaires à la gestion des données pour notre projet, en permettant le téléchargement de fichiers depuis des URLs, l’extraction de fichiers compressés, et le chargement de fichiers CSV tout en nettoyant les données manquantes. Elle simplifie ainsi les tâches courantes liées à la gestion des données dans notre système.\nLa classe GestionnaireDonnees a été créée pour gérer le téléchargement, la lecture et le traitement des jeux de données. Elle permet de :\n\nTélécharger des fichiers depuis des URLs.\nExtraire des fichiers compressés.\nCharger des fichiers CSV tout en nettoyant les données manquantes.\n\nCette classe centralise les fonctions nécessaires à la gestion des données pour notre projet et offre une solution modulaire pour ces tâches.\n\nMéthodes\n\n\n__init__(repertoire_telechargement=\"./data\")\n\nDescription:\nInitialise le répertoire de téléchargement pour stocker les fichiers téléchargés. Si le répertoire n’existe pas, il sera automatiquement créé.\nParamètres:\n- repertoire_telechargement (str) : Le chemin où les fichiers seront téléchargés. Par défaut, “./data”.\nRetourne:\n- Rien. Cette méthode configure uniquement les attributs d’instance.\nCode de la fonction:\ndef __init__(self, repertoire_telechargement=\"./data\"):\n    self.repertoire_telechargement = repertoire_telechargement\n    os.makedirs(self.repertoire_telechargement, exist_ok=True)\nExplication:\nLe constructeur utilise la fonction os.makedirs pour s’assurer que le répertoire de téléchargement existe avant toute opération. Cela évite des erreurs lors des téléchargements futurs.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\nprint(gestionnaire.repertoire_telechargement)  # \"./data\"\n\n\n\ntelecharger_fichier(url, nom_fichier)\n\nDescription:\nTélécharge un fichier à partir d’une URL donnée et l’enregistre dans le répertoire de téléchargement.\nParamètres:\n- url (str) : L’URL du fichier à télécharger.\n- nom_fichier (str) : Le nom du fichier une fois téléchargé.\nRetourne:\n- chemin (str) : Le chemin complet du fichier téléchargé.\nCode de la fonction:\ndef telecharger_fichier(self, url, nom_fichier):\n    chemin = pooch.retrieve(\n        url=url,\n        known_hash=None,\n        fname=nom_fichier,\n        path=self.repertoire_telechargement\n    )\n    return chemin\nExplication:\nCette méthode utilise pooch.retrieve pour télécharger un fichier depuis une URL et le sauvegarder dans le répertoire défini. Le chemin complet du fichier est renvoyé.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\nchemin = gestionnaire.telecharger_fichier(\"https://example.com/data.csv\", \"data.csv\")\nprint(chemin)  # \"./data/data.csv\"\n\n\n\ncharger_csv(chemin_fichier, supprimer_na=True)\n\nDescription:\nCharge un fichier CSV dans un DataFrame Pandas, avec la possibilité de supprimer les lignes contenant des valeurs manquantes.\nParamètres:\n- chemin_fichier (str) : Le chemin du fichier CSV à charger.\n- supprimer_na (bool) : Indique si les lignes contenant des valeurs manquantes doivent être supprimées (par défaut, True).\nRetourne:\n- dataframe (pd.DataFrame) : Le DataFrame contenant les données du fichier CSV.\nCode de la fonction:\ndef charger_csv(self, chemin_fichier, supprimer_na=True):\n    dataframe = pd.read_csv(chemin_fichier)\n    if supprimer_na:\n        dataframe = dataframe.dropna()\n    return dataframe\nExplication:\nCette méthode permet de charger un fichier CSV dans un DataFrame Pandas tout en offrant la possibilité de supprimer les lignes contenant des données manquantes, garantissant ainsi la qualité des données.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\ndf = gestionnaire.charger_csv(\"./data/data.csv\", supprimer_na=True)\nprint(df.head())\n\n\n\nextraire_zip(chemin_zip, dossier_extraction=None)\n\nDescription:\nExtrait le contenu d’un fichier ZIP dans un répertoire spécifié.\nParamètres:\n- chemin_zip (str) : Le chemin du fichier ZIP à extraire.\n- dossier_extraction (str) : Le répertoire où les fichiers extraits seront stockés. Par défaut, les fichiers sont extraits dans un sous-dossier nommé extracted dans le répertoire de téléchargement.\nRetourne:\n- dossier_extraction (str) : Le chemin du dossier contenant les fichiers extraits.\nCode de la fonction:\ndef extraire_zip(self, chemin_zip, dossier_extraction=None):\n    if dossier_extraction is None:\n        dossier_extraction = os.path.join(self.repertoire_telechargement, \"extracted\")\n    os.makedirs(dossier_extraction, exist_ok=True)\n    with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n        zip_ref.extractall(dossier_extraction)\n    os.remove(chemin_zip)\n    return dossier_extraction\nExplication:\nCette méthode extrait un fichier ZIP dans un répertoire spécifié ou, si aucun répertoire n’est précisé, dans un sous-dossier nommé extracted. Après extraction, le fichier ZIP est supprimé pour économiser de l’espace disque.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\nchemin_extraction = gestionnaire.extraire_zip(\"./data/archive.zip\")\nprint(chemin_extraction)  # \"./data/extracted/\"\n\nEn résumé, la classe GestionnaireDonnees centralise les opérations courantes liées à la gestion des données dans notre projet, rendant le processus plus fluide et réutilisable. Elle offre des méthodes pour télécharger des fichiers, charger des données à partir de CSV et extraire des fichiers ZIP, ce qui constitue la base de notre système de traitement des données."
  },
  {
    "objectID": "docu.html#accès-à-linterface-web",
    "href": "docu.html#accès-à-linterface-web",
    "title": "Documentation",
    "section": "9.1 Accès à l’interface web",
    "text": "9.1 Accès à l’interface web\n\nOuvrez un navigateur web (Chrome, Firefox, etc.).\nEntrez l’adresse suivante : [https://mscaia.github.io/PROJ_HAX712X/].\nExplorez les sections disponibles :"
  },
  {
    "objectID": "docu.html#téléchargement-et-traitement-des-données",
    "href": "docu.html#téléchargement-et-traitement-des-données",
    "title": "Documentation",
    "section": "9.2 Téléchargement et traitement des données",
    "text": "9.2 Téléchargement et traitement des données\n\nTéléchargez les jeux de données sur la page X\nUtilisez le menu pour :\n\nCharger un fichier CSV.\nPrétraiter les données directement dans l’interface."
  },
  {
    "objectID": "docu.html#génération-de-rapports",
    "href": "docu.html#génération-de-rapports",
    "title": "Documentation",
    "section": "9.3 Génération de rapports",
    "text": "9.3 Génération de rapports"
  },
  {
    "objectID": "docu.html#utilisation-des-prédictions",
    "href": "docu.html#utilisation-des-prédictions",
    "title": "Documentation",
    "section": "9.4 Utilisation des prédictions",
    "text": "9.4 Utilisation des prédictions"
  },
  {
    "objectID": "docu.html#dépannage",
    "href": "docu.html#dépannage",
    "title": "Documentation",
    "section": "9.5 Dépannage",
    "text": "9.5 Dépannage\nSi vous rencontrez des problèmes n’hésitez pas à nous contacter."
  },
  {
    "objectID": "auteurs.html",
    "href": "auteurs.html",
    "title": "Contributeurs",
    "section": "",
    "text": "Nous sommes étudiants en Master 1 Statistique et Science des Données (SSD) à l’Université de Montpellier. Dans le cadre du cours Développement Logiciel, nous avons collaboré sur le projet CycleVision3, combinant nos compétences pour concevoir une solution innovante dédiée à l’analyse du trafic cycliste.\n\n\nARMAND Charlotte\nCréation de cartes interactives et prévisions de trafic.\n- Email\n- GitHub Profile\n\n\n\nCONDAMY Fabian\nDéveloppement et déploiement du site web.\n- Email\n- GitHub Profile\n\n\n\nSCAIA Matteo\nAnalyse de données et création de cartes interactives et vidéos.\n- Email\n- GitHub Profile\n\n\n\nSTETSUN Kateryna\nTests et documentation du projet.\n- Email\n- GitHub Profile\n\n\n\nLICENCE\n\nCopyright 2024 SCAIA Matteo, ARMAND Charlotte, CONDAMY Fabian, STETSUN Kateryna\nPermission est accordée gratuitement à toute personne obtenant une copie de ce logiciel et des fichiers de documentation associés (le “Logiciel”), d’utiliser le Logiciel sans restriction, y compris, sans limitation, les droits d’utiliser, copier, modifier, fusionner, publier, distribuer, sous-licencier et/ou vendre des copies du Logiciel, sous réserve des conditions suivantes :\nLa notice de copyright ci-dessus et cette permission doivent être incluses dans toutes les copies ou parties substantielles du Logiciel.\nLE LOGICIEL EST FOURNI “EN L’ÉTAT”, SANS GARANTIE D’AUCUNE SORTE, EXPRESSE OU IMPLICITE, Y COMPRIS MAIS SANS S’Y LIMITER, LES GARANTIES DE QUALITÉ MARCHANDE, D’ADÉQUATION À UN USAGE PARTICULIER ET D’ABSENCE DE CONTREFAÇON. EN AUCUN CAS, LES AUTEURS OU DÉTENTEURS DU COPYRIGHT NE POURRONT ÊTRE TENUS RESPONSABLES DE TOUTE RÉCLAMATION, DOMMAGES OU AUTRE RESPONSABILITÉ, QUE CE SOIT DANS UNE ACTION CONTRACTUELLE, DÉLICTUELLE OU AUTRE, PROVENANT DU LOGICIEL OU DE SON UTILISATION OU D’AUTRES INTERACTIONS AVEC CELUI-CI."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "",
    "text": "CycleVision3 est un projet qui vise à décrire le trafic cycliste à Montpellier à travers l’analyse des quelques jeux de données suivants :\n\nTrajets à vélos en libre-service\nComptages vélo et piéton issus des compteurs de vélo\nOpenStreetMap\n\nIl s’agit principalement d’un projet de visualisation, avec des cartes (dont certaines sont interactives) et une vidéo. Les principaux projets sont disponibles dans l’onglet travaux."
  },
  {
    "objectID": "index.html#a-propos",
    "href": "index.html#a-propos",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "",
    "text": "CycleVision3 est un projet qui vise à décrire le trafic cycliste à Montpellier à travers l’analyse des quelques jeux de données suivants :\n\nTrajets à vélos en libre-service\nComptages vélo et piéton issus des compteurs de vélo\nOpenStreetMap\n\nIl s’agit principalement d’un projet de visualisation, avec des cartes (dont certaines sont interactives) et une vidéo. Les principaux projets sont disponibles dans l’onglet travaux."
  },
  {
    "objectID": "index.html#stations-de-vélos-à-montpellier.",
    "href": "index.html#stations-de-vélos-à-montpellier.",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "Stations de vélos à Montpellier.",
    "text": "Stations de vélos à Montpellier.\nCi-dessous, vous trouverez une carte interactive présentant le nombre de vélos en temps réel disponibles dans les stations de la métropole de Montpellier.\nCette carte offre une vue d’ensemble dynamique permettant de suivre l’état des stations en direct.\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "Contact",
    "text": "Contact\nPour toute question ou suggestion, n’hésitez pas à nous contacter."
  },
  {
    "objectID": "projet2.html",
    "href": "projet2.html",
    "title": "Projet 2",
    "section": "",
    "text": "Ici, les cartes issues de nos principaux travaux.\nL’application Shiny de notre carte interactive : Accéder à l’application Shiny\n\n\n\n\n\nCarte des intensités\n\n\nSélectionner une date:  Lundi Mardi Mercredi Jeudi Vendredi Samedi Dimanche \nSélectionner une heure:  00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00 18:00 19:00 20:00 21:00 22:00 23:00 \n\nAfficher la carte\n\n\n\n\n\n\n\nCarte des trajets\n\n\nSélectionner une date:  Lundi Mardi Mercredi Jeudi Vendredi Samedi Dimanche \nSélectionner une heure:  00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00 18:00 19:00 20:00 21:00 22:00 23:00 \n\nAfficher la carte"
  }
]