[
  {
    "objectID": "videos.html",
    "href": "videos.html",
    "title": "Visualisation vidéo",
    "section": "",
    "text": "Voici une visualisation vidéo des trajets simulés pour la journée du 2024-09-05.\n\n  Your browser does not support the video tag. \n\nVous pouvez également consulter les vidéos suivantes de notre galerie:\n\n\n\n\n\nVideo Gallery\n\n\n\n\n\n\n❮\n\n  Your browser does not support the video tag. \n\n❯\n\n\n\n\n\nPour en savoir plus sur la méthode employée pour générer cette vidéo, consultez la section 6.2.3 Vidéo de la documentation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "",
    "text": "CycleVision3 est un projet qui vise à décrire le trafic cycliste à Montpellier à travers l’analyse des quelques jeux de données suivants :\n\nTrajets à vélos en libre-service\nComptages vélo et piéton issus des compteurs de vélo\nOpenStreetMap\n\nIl s’agit principalement d’un projet de visualisation, avec des cartes (dont certaines sont interactives) et une vidéo. Les principaux projets sont disponibles dans l’onglet travaux."
  },
  {
    "objectID": "index.html#a-propos",
    "href": "index.html#a-propos",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "",
    "text": "CycleVision3 est un projet qui vise à décrire le trafic cycliste à Montpellier à travers l’analyse des quelques jeux de données suivants :\n\nTrajets à vélos en libre-service\nComptages vélo et piéton issus des compteurs de vélo\nOpenStreetMap\n\nIl s’agit principalement d’un projet de visualisation, avec des cartes (dont certaines sont interactives) et une vidéo. Les principaux projets sont disponibles dans l’onglet travaux."
  },
  {
    "objectID": "index.html#stations-de-vélos-à-montpellier.",
    "href": "index.html#stations-de-vélos-à-montpellier.",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "Stations de vélos à Montpellier.",
    "text": "Stations de vélos à Montpellier.\nCi-dessous, vous trouverez une carte interactive présentant le nombre de vélos en temps réel disponibles dans les stations de la métropole de Montpellier.\nCette carte offre une vue d’ensemble dynamique permettant de suivre l’état des stations en direct, avec une mise à jour automatique toutes les heures.\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Visualisation des trajets en vélo dans la ville de Montpellier.",
    "section": "Contact",
    "text": "Contact\nPour toute question ou suggestion, n’hésitez pas à nous contacter."
  },
  {
    "objectID": "auteurs.html",
    "href": "auteurs.html",
    "title": "Contributeurs",
    "section": "",
    "text": "Nous sommes étudiants en Master 1 Statistique et Science des Données (SSD) à l’Université de Montpellier. Dans le cadre du cours Développement Logiciel, nous avons collaboré sur le projet CycleVision3, combinant nos compétences pour concevoir une solution innovante dédiée à l’analyse du trafic cycliste.\n\n\n\n\n\n\nARMAND Charlotte\n\n\nCréation de cartes interactives et prévisions de trafic.\n\n\n\nEmail\n\n\nGitHub Profile\n\n\n\n\n\n\nCONDAMY Fabian\n\n\nDéveloppement et déploiement du site web.\n\n\n\nEmail\n\n\nGitHub Profile\n\n\n\n\n\n\n\n\nSCAIA Matteo\n\n\nAnalyse de données et création de cartes interactives et vidéos.\n\n\n\nEmail\n\n\nGitHub Profile\n\n\n\n\n\n\nSTETSUN Kateryna\n\n\nTests et documentation du projet, assistance développement du site web.\n\n\n\nEmail\n\n\nGitHub Profile\n\n\n\n\n\n\n\n\nLICENCE\n\nCopyright 2024 SCAIA Matteo, ARMAND Charlotte, CONDAMY Fabian, STETSUN Kateryna\nPermission est accordée gratuitement à toute personne obtenant une copie de ce logiciel et des fichiers de documentation associés (le “Logiciel”), d’utiliser le Logiciel sans restriction, y compris, sans limitation, les droits d’utiliser, copier, modifier, fusionner, publier, distribuer, sous-licencier et/ou vendre des copies du Logiciel, sous réserve des conditions suivantes :\nLa notice de copyright ci-dessus et cette permission doivent être incluses dans toutes les copies ou parties substantielles du Logiciel.\nLE LOGICIEL EST FOURNI “EN L’ÉTAT”, SANS GARANTIE D’AUCUNE SORTE, EXPRESSE OU IMPLICITE, Y COMPRIS MAIS SANS S’Y LIMITER, LES GARANTIES DE QUALITÉ MARCHANDE, D’ADÉQUATION À UN USAGE PARTICULIER ET D’ABSENCE DE CONTREFAÇON. EN AUCUN CAS, LES AUTEURS OU DÉTENTEURS DU COPYRIGHT NE POURRONT ÊTRE TENUS RESPONSABLES DE TOUTE RÉCLAMATION, DOMMAGES OU AUTRE RESPONSABILITÉ, QUE CE SOIT DANS UNE ACTION CONTRACTUELLE, DÉLICTUELLE OU AUTRE, PROVENANT DU LOGICIEL OU DE SON UTILISATION OU D’AUTRES INTERACTIONS AVEC CELUI-CI."
  },
  {
    "objectID": "analyse_donnees.html",
    "href": "analyse_donnees.html",
    "title": "Quelques éléments d’analyse des données",
    "section": "",
    "text": "Ci-dessous, quelques éléments d’analyse des données."
  },
  {
    "objectID": "analyse_donnees.html#nombre-total-de-trajets-des-différentes-années-depuis-2020.",
    "href": "analyse_donnees.html#nombre-total-de-trajets-des-différentes-années-depuis-2020.",
    "title": "Quelques éléments d’analyse des données",
    "section": "Nombre total de trajets des différentes années depuis 2020.",
    "text": "Nombre total de trajets des différentes années depuis 2020.\n\n \n\n\n \n\n\nCes graphiques illustrent l’évolution quotidienne du nombre total de trajets entre 2021 et 2024.\nOn observe une tendance générale à l’augmentation des trajets au printemps et en été, suivie d’une diminution en hiver, probablement en raison des conditions météorologiques. Les graphiques font également ressortir des lacunes dans les données fournies par la TaM, qui semblent incomplètes."
  },
  {
    "objectID": "analyse_donnees.html#comparaison-des-trajets-journaliers-entre-les-années.",
    "href": "analyse_donnees.html#comparaison-des-trajets-journaliers-entre-les-années.",
    "title": "Quelques éléments d’analyse des données",
    "section": "Comparaison des trajets journaliers entre les années.",
    "text": "Comparaison des trajets journaliers entre les années.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCes graphiques représentent une comparaison des trajets journaliers sur les quatre mêmes années, visualisés sous forme de diagrammes circulaires. Chaque graphique montre les habitudes de déplacement pour chaque jour de la semaine, réparties sur une horloge de 24 heures.\nOn observe des pics d’activité le matin et le soir, correspondant probablement aux trajets domicile-travail. Bien que les profils soient globalement similaires entre les années, de légères fluctuations sont visibles, indiquant un changement dans les comportements de déplacement ou les besoins de mobilité au fil des années."
  },
  {
    "objectID": "analyse_donnees.html#distance-moyenne-parcourue-et-stations-les-plus-populaires.",
    "href": "analyse_donnees.html#distance-moyenne-parcourue-et-stations-les-plus-populaires.",
    "title": "Quelques éléments d’analyse des données",
    "section": "Distance moyenne parcourue et stations les plus populaires.",
    "text": "Distance moyenne parcourue et stations les plus populaires.\n\n \n\n\nCes deux graphiques permettent plusieurs interprétations. Le premier illustre les stations de retour les plus populaires, c’est-à-dire celles où les cyclistes se rendent le plus fréquemment. On constate que la station ‘Boutonnet’ est en tête, suivie de près par la station ‘Place Albert 1er - St Charles’.\nLe second graphique présente l’évolution de la distance moyenne parcourue par cycliste au fil des années. On remarque un pic chaque année au mois de mai (généralement lié au retour du soleil), ainsi qu’une tendance à la baisse en fin d’année. De plus, cette tendance semble se répéter de manière similaire au cours des quatre années étudiées."
  },
  {
    "objectID": "docu.html",
    "href": "docu.html",
    "title": "Documentation",
    "section": "",
    "text": "Le projet CycleVision3 a pour objectif d’analyser et de prédire les flux cyclistes dans la ville de Montpellier à l’aide de données issues de trois sources principales :\n\nVéloMagg : Historique des trajets réalisés avec le système de vélos en libre-service.\n\nCapteurs de flux cyclistes et piétons : Données collectées à partir de dispositifs installés aux points stratégiques de la ville.\n\nOpenStreetMap (OSM) : Données géographiques ouvertes, utilisées pour la cartographie et la contextualisation des trajets.\n\nL’ambition du projet est de développer des visualisations interactives, notamment une carte prédictive des flux cyclistes, accessibles via un site web dédié. Ces outils visent à :\n\nIdentifier les tendances de mobilité pour mieux comprendre les habitudes des usagers.\n\nProposer des solutions pratiques afin d’optimiser les infrastructures urbaines et de promouvoir l’usage du vélo comme moyen de transport durable.\n\nEn combinant innovation technologique et impact sociétal, CycleVision3 s’inscrit dans une démarche adaptable à d’autres contextes urbains. Ce projet contribue ainsi à la réflexion autour de la mobilité intelligente et durable, répondant aux enjeux croissants des villes contemporaines."
  },
  {
    "objectID": "docu.html#structure-du-projet",
    "href": "docu.html#structure-du-projet",
    "title": "Documentation",
    "section": "2.1 Structure du projet",
    "text": "2.1 Structure du projet\nLa structure du projet est conçue pour garantir une séparation claire des composantes essentielles à l’analyse et à la création des visualisations. Voici un aperçu de l’organisation des fichiers et répertoires :\n\n\nVoir la structure\n\nmain/                                           # Répertoire principal du projet\n├── .github/workflows/                          # Automatisation des actions GitHub\n│   ├── update_and_deploy.yml                   # Configuration pour les mises à jour et déploiements automatiques\n├── Cycle3/                                     # Dossier principal avec les codes de programme\n│   ├── analyse_donnee/                         # Scripts pour l'analyse exploratoire des données\n│   │   ├── cache/\n│   │   ├── __init__.py\n│   │   └── statistique.py\n│   ├── docs/                                   # Configuration et génération de la documentation avec Sphinx\n│   │   ├── build/html/\n│   │   ├── cache/\n│   │   ├── conf.py\n│   │   ├── make.bat\n│   │   ├── Makefile\n│   │   ├── index.rst\n│   │   └── ...                                 # D'autres fichiers au format .rst\n│   ├── images/                                 # Images utilisées dans le projet\n│   ├── map/                                    # Scripts pour les cartes interactives\n│   │   ├── __init__.py  \n│   │   ├── carte.py\n│   │   ├── map.py\n│   │   └── map_trajet_BD.py\n│   ├── prediction/                            # Scripts pour les cartes de prediction\n│   │   ├── __init__.py  \n│   │   └── prediction.py                   \n│   ├── vidéo/                                 # Scripts pour les video\n│   │   ├── __init__.py  \n│   │   └── vidéo.py\n│   ├── visualisation/                          # Résultats des visualisations\n├── cache/\n├── data/                                       # Données pour l'analyse\n│   ├── extracted/                              # Données extraites\n│   ├── CoursesVelomagg.csv                     # Données des trajets VéloMagg\n│   ├── video.csv                               # Données vidéo\n│   └── video_avec_coord.csv                    # Données vidéo enrichies avec coordonnées\n├── docs/                                       # Contenu et configuration du site web\n│   ├── _freeze/\n│   ├── cache/  \n│   ├── docu_files/                             # Fichiers affichés sur la page \"Documentation\"\n│   ├── ...                                     # Fichiers affichés pour d'autres pages\n│   ├── shiny_app/                              # Application interactive pour explorer les données\n│   ├── styles.css                              # Feuille de style pour le site\n│   └── ...                                     # Autres fichiers nécessaires\n├── roadmap/                                    # Documentation de la planification initiale du projet\n├── slide/                                      # Fichiers liés à la présentation finale\n│   ├── cache/\n│   ├── images/\n│   ├── slide_files/libs/\n│   ├── slide.html                              # Version exportée des diapositives\n│   ├── slide.qmd                               # Contenu principal des diapositives\n│   ├── slides-styles.scss                      # Feuille de style pour la personnalisation des diapositives\n│   ├── slide.css                               # Feuille de style pour la personnalisation des diapositives\n│   └── ...                                     # Autres fichiers nécessaires\n├── src/                                        # Répertoire contenant le code source\n│   ├── __init__.py\n│   ├── donnée.py                               # Fonctions de traitement des données\n│   ├── fonctions_basedonnees.py                # Fonctions pour les bases de données\n│   └── gestion_donnee.py                       # Classe \"GestionnaireDonnees\" pour le traitement des données\n├── test/                                       # Répertoire contenant le code pour les tests\n├── .gitignore                                  # Liste des fichiers ignorés par Git\n├── LICENCE                                     # Informations sur la licence du projet\n├── README.md                                   # Résumé et instructions pour exécuter le projet\n└── requirements.txt                            # Liste des bibliothèques et dépendances nécessaires"
  },
  {
    "objectID": "docu.html#installation-et-dépendances",
    "href": "docu.html#installation-et-dépendances",
    "title": "Documentation",
    "section": "2.2 Installation et dépendances",
    "text": "2.2 Installation et dépendances\nAvant de commencer le développement et l’analyse des données, il est nécessaire de configurer l’environnement de travail en installant toutes les dépendances requises. Suivez les étapes ci-dessous pour configurer rapidement et exécuter le projet :\n\nCloner le dépôt\n\nClonez le répertoire du projet et accédez-y\ngit clone https://github.com/mscaia/PROJ_HAX712X.git\ncd PROJ_HAX712X\n\nConfigurer l’environnement\n\nCréez et activez un environnement virtuel avec Conda\nconda create --name Cycle3 python=3.9.18\nconda activate Cycle3\nInstallez les dépendances listées dans requirements.txt\npip install -r requirements.txt\n\nExécuter les scripts\n\nPour plus de détails sur les visualisations et les fonctionnalités avancées, consultez la section 9. Guide de l’utilisateur."
  },
  {
    "objectID": "docu.html#configuration-des-fichiers",
    "href": "docu.html#configuration-des-fichiers",
    "title": "Documentation",
    "section": "2.3 Configuration des fichiers",
    "text": "2.3 Configuration des fichiers\nLe projet est configuré de manière à utiliser Quarto pour la création du site web interactif. Toute la documentation a été initialement rédigée en utilisant des fichiers .qmd, en cohérence avec le reste du site.\nLe fichier _quarto.yml contient les paramètres de configuration du projet Quarto, tandis que le fichier index.qmd contient le contenu principal de la page d’accueil du site."
  },
  {
    "objectID": "docu.html#base-de-données-et-traitement-des-données",
    "href": "docu.html#base-de-données-et-traitement-des-données",
    "title": "Documentation",
    "section": "2.4 Base de données et traitement des données",
    "text": "2.4 Base de données et traitement des données\nLes principaux jeux de données sont stockés dans le répertoire data/ et comprennent :\n\nCoursesVelomagg.csv : Historique des trajets en vélos libres.\n\nvideo.csv et video_avec_coord.csv : Données vidéo pour l’analyse spatiale.\n\nLe traitement des données est assuré par les scripts situés dans le répertoire src/ :\n\ndonnée.py : Fonctions pour gérer et structurer les données brutes.\n\nfonctions_basedonnees.py : Fonctions spécifiques aux bases de données.\n\ngestion_donnee.py : Classe principale pour le traitement et la transformation des données.\n\nLes résultats de l’analyse sont exploités dans le répertoire Cycle3/, qui contient notamment des scripts pour :\n\nL’analyse exploratoire des données (analyse_donnee/).\n\nLa visualisation cartographique (map/).\n\nLa modélisation prédictive (prediction/).\nLa génération de vidéos (video/)."
  },
  {
    "objectID": "docu.html#exécution-du-projet",
    "href": "docu.html#exécution-du-projet",
    "title": "Documentation",
    "section": "2.5 Exécution du projet",
    "text": "2.5 Exécution du projet\nL’exécution du projet génère des visualisations interactives et des cartes prédictives grâce à :\n\nFolium : Création de cartes interactives.\n\nMatplotlib : Graphiques statistiques.\n\nLes résultats sont stockés dans Cycle3/visualisation/ et incluent des cartes des trajets et des prévisions de trafic."
  },
  {
    "objectID": "docu.html#documentation-et-tests",
    "href": "docu.html#documentation-et-tests",
    "title": "Documentation",
    "section": "2.6 Documentation et tests",
    "text": "2.6 Documentation et tests\nPour garantir la qualité du code, le projet intègre :\n\nTests Unitaires : Vérification des fonctionnalités principales.\n\nDocumentation Technique : Rédigée avec Quarto pour détailler les API, les méthodes et les résultats. Une tentative de création avec Sphinx a été effectuée, mais elle n’a pas abouti en raison de difficultés techniques."
  },
  {
    "objectID": "docu.html#prétraitement-et-nettoyage-des-données",
    "href": "docu.html#prétraitement-et-nettoyage-des-données",
    "title": "Documentation",
    "section": "4.1 Prétraitement et Nettoyage des Données",
    "text": "4.1 Prétraitement et Nettoyage des Données\n\nÉtapes réalisées :\nLe nettoyage et le prétraitement des données ont constitué une étape fondamentale pour assurer la qualité et la cohérence des données utilisées dans l’analyse. Les principales actions entreprises sont les suivantes :\n\nValidation des données : Identification et traitement des anomalies, telles que les valeurs aberrantes et les doublons, avec une gestion des valeurs manquantes en fonction de leur impact sur l’analyse.\nFormatage temporel et géographique : Conversion des champs de dates pour permettre une analyse chronologique, et standardisation des adresses et coordonnées géographiques pour optimiser la géolocalisation.\n\nCette phase a permis de préparer des données propres et fiables, essentielles pour l’analyse et la création des visualisations."
  },
  {
    "objectID": "docu.html#visualisation-et-cartographie-du-trafic",
    "href": "docu.html#visualisation-et-cartographie-du-trafic",
    "title": "Documentation",
    "section": "4.2 Visualisation et Cartographie du Trafic",
    "text": "4.2 Visualisation et Cartographie du Trafic\n\nÉtapes réalisées :\nLes données traitées ont été intégrées dans des visualisations interactives et des cartes dynamiques pour illustrer le trafic cycliste à Montpellier. Les actions clés incluent :\n\nCréation de cartes interactives : Utilisation de la bibliothèque Folium pour développer une carte dynamique présentant les stations de vélos, les itinéraires fréquentés, et les zones de densité de trafic.\nCalcul des itinéraires : Emploi de la bibliothèque OSMnx pour déterminer les itinéraires entre les stations, mettant en évidence les parcours les plus utilisés et permettant l’analyse des variations temporelles du trafic.\n\nCes visualisations ont été des outils essentiels pour la compréhension des tendances du trafic cycliste, facilitant l’analyse et la prise de décisions éclairées pour les phases suivantes du projet."
  },
  {
    "objectID": "docu.html#développement-de-linterface-web",
    "href": "docu.html#développement-de-linterface-web",
    "title": "Documentation",
    "section": "4.3 Développement de l’Interface Web",
    "text": "4.3 Développement de l’Interface Web\nLe projet s’est concrétisé par la création d’un site web interactif développé avec Quarto, intégrant :\n\nLes visualisations interactives produites lors de l’analyse.\nUne carte prédictive du trafic cycliste, permettant d’estimer les flux de vélos pour le lendemain en fonction des données historiques.\n\nCette interface a été conçue pour offrir une navigation fluide et intuitive, rendant les résultats accessibles aux utilisateurs de vélos. Elle constitue un outil complet pour l’analyse des données et la planification urbaine, tout en favorisant la promotion de la mobilité durable."
  },
  {
    "objectID": "docu.html#acquisition-des-données",
    "href": "docu.html#acquisition-des-données",
    "title": "Documentation",
    "section": "5.1 Acquisition des données",
    "text": "5.1 Acquisition des données\nLes ensembles de données ont été obtenus à partir de sources officielles :\n\nDonnées VéloMagg : Historique des trajets réalisés via le système de vélos en libre-service.\nComptages cyclistes et piétons : Données de comptage obtenues par des capteurs installés à des points stratégiques de la ville.\nDonnées OpenStreetMap (OSM) : Informations géographiques utilisées pour la cartographie des trajets.\n\nLes fichiers ont été extraits sous les formats .csv et .json et chargés à l’aide de la bibliothèque pandas. Une validation initiale a été réalisée pour vérifier l’intégrité des fichiers (taille, colonnes attendues, etc.)."
  },
  {
    "objectID": "docu.html#prétraitement",
    "href": "docu.html#prétraitement",
    "title": "Documentation",
    "section": "5.2 Prétraitement",
    "text": "5.2 Prétraitement\nL’étape de prétraitement vise à rendre les données prêtes pour l’analyse. Les principales opérations incluent :\n\nNettoyage des données : Suppression des valeurs manquantes et des doublons afin de garantir la cohérence des données.\nTransformation des variables : Normalisation des données temporelles pour assurer une harmonisation des différents jeux de données.\n\nCes étapes ont permis de préparer un jeu de données fiable pour l’analyse et la modélisation."
  },
  {
    "objectID": "docu.html#analyse-exploratoire",
    "href": "docu.html#analyse-exploratoire",
    "title": "Documentation",
    "section": "5.3 Analyse exploratoire",
    "text": "5.3 Analyse exploratoire\nUne analyse préliminaire des données a permis de dégager plusieurs tendances importantes :\n\nAnalyse temporelle des flux : Identification des variations du trafic cycliste selon l’heure, le jour et le mois.\nCartographie du trafic : Création de cartes interactives avec Folium pour visualiser les zones de forte densité de trafic.\nVisualisation des variations de trafic : Observation des fluctuations de la densité du trafic à travers la ville.\n\nCette analyse exploratoire a guidé les choix méthodologiques pour les étapes suivantes, notamment la modélisation du trafic."
  },
  {
    "objectID": "docu.html#modélisation",
    "href": "docu.html#modélisation",
    "title": "Documentation",
    "section": "5.4 Modélisation",
    "text": "5.4 Modélisation\nUn algorithme de prédiction du trafic cycliste a été conçu en prenant en compte plusieurs variables clés :\n\nDonnées historiques des trajets : Utilisation des trajets passés pour identifier des tendances.\nLocalisation et fréquence des trajets : Analyse des points de départ et d’arrivée, ainsi que des fréquences de passage.\n\nLe modèle repose sur l’analyse des données disponibles pour estimer les flux futurs de trafic, en se basant sur les tendances observées dans les trajets passés et leur répartition géographique."
  },
  {
    "objectID": "docu.html#visualisation",
    "href": "docu.html#visualisation",
    "title": "Documentation",
    "section": "5.5 Visualisation",
    "text": "5.5 Visualisation\nLes résultats du projet sont présentés à travers diverses visualisations interactives, permettant une exploration approfondie des données :\n\nCartes des trajets : Visualisation des trajets réalisés par les cyclistes, avec une mise en évidence des zones de forte densité de trafic.\nCartes prédictives : Représentation des trajectoires prévues pour le trafic cycliste basé sur les données historiques.\nCarte des stations de vélos de Montpellier : Localisation des stations de vélos en libre-service à travers la ville, permettant une meilleure compréhension des points d’accès aux vélos.\nVisualisation vidéo : Une vidéo illustrant l’évolution du trafic cycliste sur une journée complète, générée à partir des données du projet.\n\nToutes ces visualisations sont accessibles directement via le site web interactif du projet, offrant ainsi une interface intuitive pour l’exploration des flux cyclistes et des prédictions."
  },
  {
    "objectID": "docu.html#intégration",
    "href": "docu.html#intégration",
    "title": "Documentation",
    "section": "5.6 Intégration",
    "text": "5.6 Intégration\nLe pipeline a été conçu pour être flexible et évolutif afin de répondre aux besoins futurs du projet :\n\nPortabilité : Le système peut être facilement adapté à d’autres villes disposant de systèmes de vélos en libre-service similaires, permettant ainsi une application étendue de la méthodologie.\nScalabilité : Le pipeline est conçu pour intégrer de nouveaux types de données, tels que celles concernant la pollution de l’air ou les conditions météorologiques, pour affiner les prédictions et les analyses."
  },
  {
    "objectID": "docu.html#bibliothèques-utilisées",
    "href": "docu.html#bibliothèques-utilisées",
    "title": "Documentation",
    "section": "6.1 Bibliothèques utilisées",
    "text": "6.1 Bibliothèques utilisées\nDans le cadre de ce projet, plusieurs bibliothèques ont été utilisées pour répondre aux différents besoins techniques et analytiques. Voici une présentation des bibliothèques principales et leur rôle.\n\n\nconcurrent.futures.ThreadPoolExecutor\n\nThreadPoolExecutor est une fonctionnalité du module standard concurrent.futures pour exécuter des tâches en parallèle.\nElle est utilisée pour optimiser le traitement des données et accélérer le rendu des animations dans le cadre de ce projet.\n\n\n\ncsv\n\nLa bibliothèque csv permet de lire et d’écrire des fichiers CSV, un format commun pour manipuler des données tabulaires.\nNous avons utilisé csv pour extraire et traiter les données brutes contenues dans des fichiers au format CSV. Cela est particulièrement utile pour manipuler des ensembles de données simples où une lecture ligne par ligne est nécessaire.\n\n\n\ndatetime\n\ndatetime est un module intégré pour manipuler les dates et les heures.\nDans le projet, il est employé pour traiter les données temporelles des trajets cyclistes et synchroniser les animations avec les horodatages.\n\n\n\nfolium\n\nfolium est une bibliothèque dédiée à la création de cartes interactives.\nNous avons utilisé folium pour visualiser les trajets et itinéraires des vélos sur des cartes interactives, permettant une meilleure compréhension géographique des données.\n\n\n\nfunctools.lru_cache\n\nfunctools.lru_cache est une fonctionnalité de Python pour optimiser les performances.\nEn mettant en cache les résultats des fonctions fréquemment appelées, functools.lru_cache améliore les performances et réduit le temps de calcul pour des opérations répétées.\n\n\n\njson\n\njson est utilisée pour manipuler des données au format JSON, un standard de stockage et d’échange d’informations structurées.\nNous utilisons json pour lire et écrire des données structurées, notamment pour gérer les configurations et les résultats intermédiaires dans des fichiers légers.\n\n\n\nmatplotlib.animation.FuncAnimation et FFMpegWriter\n\nCes modules de la bibliothèque matplotlib.animation permettent de créer des animations et d’exporter celles-ci sous forme de fichiers vidéo.\nDans le projet, ils sont utilisés pour générer des animations illustrant les variations temporelles du trafic cycliste et les enregistrer sous un format visuel accessible.\n\n\n\nmatplotlib.pyplot\n\nmatplotlib.pyplot est utilisée pour produire des graphiques statiques et des visualisations animées.\nDans ce projet, elle permet de créer des graphiques dynamiques illustrant les trajectoires cyclistes et d’exporter ces visualisations sous forme de vidéos à l’aide des modules FuncAnimation et FFMpegWriter.\n\n\n\nnetworkx\n\nnetworkx est une bibliothèque dédiée à la création, la manipulation et l’analyse de graphes complexes.\nDans ce projet, elle est utilisée pour représenter et étudier les réseaux cyclistes, notamment pour visualiser les trajets et calculer les chemins les plus courts entre les nœuds.\n\n\n\nnumpy\n\nnumpy est une bibliothèque puissante pour effectuer des calculs numériques avancés, notamment des opérations matricielles.\nLes opérations matricielles et les calculs numériques complexes nécessaires à l’analyse des données sont simplifiés grâce à numpy, qui garantit également des performances élevées.\n\n\n\nos\n\nos fournit des fonctions pour interagir avec le système d’exploitation, notamment pour gérer les fichiers et les répertoires.\nNous avons utilisé os pour gérer les chemins des fichiers, vérifier l’existence des répertoires, et manipuler les ressources locales du système.\n\n\n\nosmnx\n\nosmnx est utilisée pour le géocodage et l’analyse des réseaux géographiques.\nCette bibliothèque permet d’extraire des données géographiques d’OpenStreetMap, de construire des graphes routiers, et d’analyser les itinéraires et les trajets cyclistes dans le cadre de ce projet.\n\n\n\npandas\n\npandas est essentielle pour manipuler et analyser des données tabulaires de manière efficace.\npandas est utilisée pour nettoyer, transformer et analyser des ensembles de données complexes, offrant des fonctionnalités avancées comme le traitement des séries temporelles et des jointures de tables.\n\n\n\npooch\n\npooch facilite le téléchargement et la mise en cache des fichiers nécessaires à l’exécution du projet.\nCette bibliothèque permet de garantir un accès fiable aux données externes en les téléchargeant automatiquement et en les stockant localement pour une réutilisation future.\n\n\n\nre\n\nLa bibliothèque re permet de travailler avec des expressions régulières pour manipuler des chaînes de caractères.\nGrâce à re, nous avons pu extraire des informations spécifiques des chaînes de caractères et nettoyer les données textuelles de manière efficace.\n\n\n\nscikit-learn\n\nscikit-learn fournit des outils pour l’analyse des données et du machine learning, nous l’utilisons implicitement dans l’application shiny.\n\n\n\nshiny\n\nshiny est une bibliothèque permettant de créer des applications web interactives pour mieux visualiser et analyser des données, il nous a permis ici de contourner l’aspect statique du site Quarto.\n\n\n\nshinyswatch\n\nshinyswatch est un module qui vient en complément de shiny et qui permet de personnaliser l’apparence des applications grâce à l’intégration de thèmes préconfigurés.\n\n\n\nunicodedata\n\nunicodedata est utilisée pour normaliser les chaînes de caractères Unicode.\nCette bibliothèque est essentielle pour traiter les caractères spéciaux et garantir la cohérence des chaînes de caractères provenant de différentes sources.\n\n\n\nzipfile\n\nLa bibliothèque zipfile permet de travailler avec des fichiers au format ZIP, un format couramment utilisé pour la compression et l’archivage de fichiers.\nNous avons utilisé zipfile pour extraire des fichiers compressés afin de récupérer les données nécessaires à notre projet. Cette bibliothèque offre une interface simple pour l’extraction, la création et la gestion des archives ZIP, ce qui facilite le traitement des données compressées."
  },
  {
    "objectID": "docu.html#fonctions-utilisées",
    "href": "docu.html#fonctions-utilisées",
    "title": "Documentation",
    "section": "6.2 Fonctions utilisées",
    "text": "6.2 Fonctions utilisées\n\n6.2.1 Map\n\nFonctions de traitement des données\n\n\ncolonne(i, w_file)\n\nDescription:\nCette fonction permet d’extraire une colonne spécifique d’un fichier CSV. Elle prend en entrée un indice i, représentant la colonne à extraire, ainsi que le chemin du fichier w_file. La fonction ouvre le fichier, parcourt chaque ligne et récupère l’élément situé à la position i dans chaque ligne.\nParamètres:\n- i (int) : L’indice de la colonne à extraire.\n- w_file (str) : Le chemin d’accès au fichier CSV.\nRetourne:\n- L (list) : Une liste contenant les valeurs de la colonne spécifiée.\nCode de la fonction:\ndef colonne(i, w_file):\n    L = []\n    with open(w_file) as f:\n        for line in f:\n            x = line.split(\",\")\n            L.append(x[i])\n    return L\nExemple d’utilisation:\nSupposons un fichier data.csv contenant :\nname,age,city\nAlice,30,Paris\nBob,25,Lyon\nAppeler colonne(1, \"data.csv\") retourne [30, 25].\n\n\n\narg(k, i, j, w_file)\n\nDescription:\nCette fonction extrait les données correspondant à une clé k dans un fichier CSV et retourne les valeurs des colonnes spécifiées par i et j.\nParamètres:\n- k (str) : La clé utilisée pour filtrer les données.\n- i (int) : L’indice de la colonne contenant les clés.\n- j (int) : L’indice de la colonne à retourner.\n- w_file (str) : Le chemin d’accès au fichier CSV.\nRetourne:\n- L (list) : Une liste contenant les valeurs correspondantes.\nCode de la fonction:\ndef arg(k, i, j, w_file):\n    L = []\n    with open(w_file) as f:\n        for line in f:\n            x = line.split(\",\")\n            if x[i] == k:\n                L.append(x[j])\n    return L\nExemple d’utilisation:\nPour le fichier data.csv ci-dessus, appeler arg(\"Alice\", 0, 2, \"data.csv\") retourne [Paris].\n\n\n\nFonctions d’adresse et de géocodage\n\n\nnettoyer_adresse_normalise(adresse)\n\nDescription:\nNettoie et normalise une adresse en supprimant les numéros au début, en normalisant les caractères Unicode..\nParamètres:\n- adresse (str) : L’adresse à normaliser.\nRetourne:\n- adresse (str) : L’adresse nettoyée et normalisée.\nCode de la fonction:\ndef nettoyer_adresse_normalise(adresse):\n    # Tenter de corriger l'encodage si nécessaire\n    try:\n        # Encode la chaîne en latin1 puis décode en utf-8\n        adresse = adresse.encode('latin1').decode('utf-8')\n    except (UnicodeEncodeError, UnicodeDecodeError):\n        pass  # Ignore les erreurs d'encodage si elles se produisent\n\n    # Supprimer les numéros ou autres formats non pertinents (ex: 057 au début)\n    adresse = re.sub(r'^\\d+\\s*', '', adresse)  # Enlève les numéros au début\n    \n    # Normalisation des caractères Unicode\n    adresse = unicodedata.normalize('NFKD', adresse)\n    \n    # Retourner l'adresse nettoyée et normalisée\n    return adresse  # Enlever les espaces supplémentaires aux extrémités\nExemple avant/après:\n- Avant : \"  12, Rue de la République  \"\n- Après : \"12 rue de la république\"\n\n\n\ncoordonne(station)\n\nDescription :\nLa fonction coordonne utilise le géocodage pour obtenir les coordonnées géographiques (latitude, longitude) d’une station donnée dans la ville de Montpellier, France.\nParamètres :\n\n\nstation (str) : Le nom de la station à géocoder.\n\n\nRetourne :\n\n\nlatitude (float) : La latitude de la station.\n\n\nlongitude (float) : La longitude de la station.\n\n\nCode de la fonction :\n  def coordonne(station):\n    try:\n        # Recherche de l'emplacement en utilisant osmnx\n        location = ox.geocode(f\"{station}, Montpellier, France\")\n        return location[0], location[1]\n    except Exception as e:\n        print(f\"Erreur pour la station {station}: {e}\")\n        return None, None\n\n\n\nFonctions liées à la carte\n\n\ngen_carte_trajet(ligne, G, m, index_colonne_départ, index_colonne_arrive,couleur)\n\nDescription:\nGénère une carte interactive affichant le trajet le plus court entre deux points.\nParamètres:\n\n\n\nligne (list) : Une ligne contenant les noms des stations de départ et d’arrivée.\n\n\nG (Graph) : Le graphe représentant le réseau de rues de la ville.\n\n\nm (Map) : L’objet de la carte sur lequel le trajet sera tracé.\n\n\nindex_colonne_départ (int) : L’indice de la colonne contenant le nom de la station de départ.\n\n\nindex_colonne_arrive (int) : L’indice de la colonne contenant le nom de la station d’arrivée.\n\n\ncouleur (str) : La couleur de la ligne représentant le trajet.\n\n\nRetourne:\n- folium.Map (Map) : La carte mise à jour avec le trajet et les marqueurs des points de départ et d’arrivée..\nCode de la fonction:\ndef gen_carte_trajet(ligne, G, m, index_colonne_départ, index_colonne_arrive,couleur):\n    # Essayer de géocoder les stations de départ et d'arrivée\n    try:\n        origin = ox.geocode(f\"{ligne[index_colonne_départ]}, Montpellier, France\")  # Première colonne\n        destination = ox.geocode(f\"{ligne[index_colonne_arrive]}, Montpellier, France\")  # Deuxième colonne\n        \n        # Vérifier si le géocodage a réussi\n        if origin is None or destination is None:\n            print(f\"Erreur de géocodage pour les stations : {ligne[index_colonne_départ]} ou {ligne[index_colonne_arrive]}\")\n            return m\n        \n        # Trouver les noeuds les plus proches de l'origine et de la destination\n        origin_node = ox.nearest_nodes(G, origin[1], origin[0])  # longitude, latitude\n        destination_node = ox.nearest_nodes(G, destination[1], destination[0])  # longitude, latitude\n\n        # Calculer l'itinéraire aller et retour\n        route = ox.shortest_path(G, origin_node, destination_node)\n\n        # Fonction pour convertir un itinéraire (liste de noeuds) en liste de coordonnées géographiques\n        def route_to_coords(G, route):\n            route_coords = []\n            for node in route:\n                point = (G.nodes[node]['y'], G.nodes[node]['x'])  # latitude, longitude\n                route_coords.append(point)\n            return route_coords\n\n        # Obtenir les coordonnées pour l'itinéraire\n        route_coords = route_to_coords(G, route)\n\n        # Ajouter l'itinéraire aller (en rouge) à la carte\n        folium.PolyLine(locations=route_coords, color=couleur, weight=5, opacity=0.75).add_to(m)\n\n        # Ajouter des marqueurs pour l'origine et la destination\n        départ_lat, départ_lon = route_coords[0]\n        arr_lat, arr_lon = route_coords[-1]  # Utiliser le dernier point pour l'arrivée\n        folium.Marker(location=[départ_lat, départ_lon], popup=f\"{ligne[index_colonne_départ]},Départ\").add_to(m)\n        folium.Marker(location=[arr_lat, arr_lon], popup=f\"{ligne[index_colonne_arrive]},arrivé\").add_to(m)\n\n    except Exception as e:\n        print(f\"Une erreur est survenue : {e}\")\n    \n    return m\n\n\n\nintensity_to_color(intens, min_in, max_in)\n\nDescription:\nLa fonction renvoie un code couleur pour une intensité donnée.\nParamètres:\n- intens (int): L’intensité qu’on cherche à représenter. - min_in (int): L’intensité minimale à représenter. Elle correspond au minimum de l’échelle de couleur. - max_in (int): L’intensité maximale à représenter. Elle correspond au maximum de l’échelle de couleur.\nRetourne:\n- rgba({}, {}, {}, {}) (arg): Le code couleur RGB associé à l’intensité à représenter.\nCode de la fonction:\ndef intensity_to_color(intens, min_in, max_in): \n    \"\"\"\n    Description: \n    La fonction 'intensity_to_color' renvoie un code couleur pour une intensité donnée.  \n    \n    Args: \n    intens : int \n    L'intensité qu'on cherche à représenter. \n    min_in : int \n    L'intensité minimale à représenter. Elle correspond au minimum de l'échelle de couleur. \n    max_in : int \n    L'intensité maximale à représenter. Elle correspond au maximum de l'échelle de couleur. \n        \n    Returns: \n    'rgba({}, {}, {}, {})'  : str \n    Le code couleur RGB associé à l'intensité à représenter. \n    \"\"\"\n    norm_in = (intens - min_in) / (max_in - min_in)\n    color = plt.cm.RdYlGn_r(norm_in)  # Colormap GnYlRd(vert à rouge)\n    return 'rgba({}, {}, {}, {})'.format(int(color[0] * 255), int(color[1] * 255), int(color[2] * 255), 1)\nExemple d’utilisation: Suppososns qu’on veuille représenter la valeur 12 sur une échelle allant de 6 à 18\nAppeler intensity_to_color(12, 6, 18) retourne rgba(254, 254, 189, 1)\n\n\n\nmap_jour(j, style, jour)\n\nDescription:\nLa fonction génère une carte des intensités moyennes observées un jour de la semaine j.\nParamètres:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\n- style (int): Le numéro (0 ou 1) correspondant au style voulu. 0 donnera une carte avec uniquement des points de différentes couleur et 1 donnera une carte avec ces points mais également la carte de chaleur (Heatmap) associée. - jour (str): Le jour de la semaine voulu (format Jour).\nRetourne:\n- La carte a été générée et sauvegardée sous le nom, nom (str, str) : Un message de validation de création de la carte et le nom sous lequel elle a été enregistrée.\nCode de la fonction:\ndef map_jour(j, style,jour):# entrée 0-6 pour les jours de la semaine, 0-1 sans-avec chaleur\n    \"\"\"\n    Description: \n    La fonction 'map_jour' génère une carte des intensités moyennes observées un jour de la semaine j. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n    - style : int\n        Le numéro (0 ou 1) correspondant au style voulu. 0 donnera une carte avec uniquement des points de différentes couleur et 1 donnera une carte avec ces points mais également la carte de chaleur (Heatmap) associée. \n    - jour : str\n        Le nom du jour correspondant (par exemple, \"Lundi\", \"Mardi\", etc.), utilisé pour nommer les fichiers générés.\n        \n    Returns: \n    - 'La carte a été générée et sauvegardée sous le nom', nom : str, str \n        Un message de validation de création de la carte et le nom sous lequel elle a été enregistrée. \n    \"\"\"\n    data = mean_intens(j)\n    intensities = [d[0] for d in data]\n    min_in = min(intensities)\n    max_in = max(intensities)\n\n    # Centrer \n    ville = \"Montpellier, France\"\n    location = ox.geocode(ville)\n    m = folium.Map(location=location, zoom_start=12)\n\n\n    # Ajouter les points sur la carte\n    for intensity, coord in data:\n        lon, lat = coord[1], coord[0]# Inversion des valeurs\n        if abs(lon-location[0])&lt;1 and abs(lat-location[1])&lt;1:\n            color = intensity_to_color(intensity, min_in, max_in)\n            folium.CircleMarker(\n                location=[lon, lat],\n                radius=8,\n                popup=f\"{intensity}\",\n                color=color,\n                fill=True,\n                fill_color=color,\n                fill_opacity=0.6\n                ).add_to(m)\n            \n    legend_html =\"\"\"\n&lt;div style=\"\n            position: fixed;\n            bottom: 50px;\n            left: 50px;\n            width: 220px;\n            height: 120px;\n            background-color: white;\n            border: 2px solid grey;\n            z-index: 9999;\n            font-size: 14px;\n            padding: 10px;\n            \"&gt;\n            &lt;b&gt;Nombre de passages:&lt;/b&gt;\n            &lt;div style=\"\n                height: 20px;\n                background: linear-gradient(to right, #008000, #f1fd4d, #f20000);\n                margin: 10px 0;\n                \"&gt;\n            &lt;/div&gt;\n            &lt;div style=\"display: flex; justify-content: space-between;\"&gt;\n                &lt;span&gt;Faible&lt;/span&gt;\n                &lt;span&gt;Élevé&lt;/span&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    \"\"\"\n\n    m.get_root().html.add_child(folium.Element(legend_html))\n    # Choix de chaleur ou non\n    if style==0:\n        nom=f'intensity_{j}.html'\n        m.save(f'./Cycle3/visualisation/{jour}/intensité/{nom}')\n        return \"La carte a été générée et sauvegardée sous le nom\", nom\n    \n    else:\n        heat_data = [[coord[1], coord[0], intensity] for intensity, coord in data]\n        HeatMap(heat_data).add_to(m)\n        nom=f'intensity_{j}_heat.html'\n        m.save(f'./Cycle3/visualisation/{jour}/intensité/{nom}')\n        return\"La carte a été générée et sauvegardée sous le nom\", nom \n\n\n\nmap_jour_h(j, h,style,jour)\n\nDescription:\nLa fonction génère une carte des intensités moyennes observées un jour de la semaine j à une heure h.\nParamètres:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu. - h (int): Le numéro de l’heure (entre 0 et 23) voulue. - style (int): Le numéro (0 ou 1) correspondant au style voulu. 0 donnera une carte avec uniquement des points de différentes couleur et 1 donnera une carte avec ces points mais également la carte de chaleur (Heatmap) associée. - jour (str): Le jour voulu (format Jour).\nRetourne:\n- 'La carte a été générée et sauvegardée sous le nom', nom (str, str): Un message de validation de création de la carte et le nom sous lequel elle a été enregistrée.\nCode de la fonction:\ndef map_jour_h(j, h,style,jour):# Entrée 0-6 pour les jours de la semaine, 0-1 sans-avec chaleur\n    \"\"\"\n    Description: \n    La fonction 'map_jour_h' génère une carte des intensités moyennes observées un jour de la semaine j à une heure h. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n    - h : int\n        Le numéro de l'heure voulue (entre 0 et 23, 0 étant la plage horraire 00h00- 00h59). \n    - style : int\n        Le numéro (0 ou 1) correspondant au style voulu. 0 donnera une carte avec uniquement des points de différentes couleur et 1 donnera une carte avec ces points mais également la carte de chaleur (Heatmap) associée. \n    - jour : str\n        Le nom du jour correspondant (par exemple, \"Lundi\", \"Mardi\", etc.), utilisé pour nommer les fichiers générés.\n        \n    Returns: \n    - 'La carte a été générée et sauvegardée sous le nom', nom : str, str \n        Un message de validation de création de la carte et le nom sous lequel elle a été enregistrée. \n    \"\"\"    \n    data = mean_intens(j)\n    p=poids_par_h(j)\n    intensities = [d[0]*p[h][1]/100 for d in data]\n    min_in = min(intensities)\n    max_in = max(intensities)\n\n    # Centrer \n    ville = \"Montpellier, France\"\n    location = ox.geocode(ville)\n    m = folium.Map(location=location, zoom_start=12)\n\n\n    # Ajouter les points sur la carte\n    for intensity, coord in data:\n        newint=intensity*p[h][1]/100\n        lon, lat = coord[1], coord[0]# Inversion des valeurs\n        if abs(lon-location[0])&lt;1 and abs(lat-location[1])&lt;1:\n            color = intensity_to_color(newint, min_in, max_in)\n            folium.CircleMarker(\n                location=[lon, lat],\n                radius=8,\n                popup=f\"{newint}\",\n                color=color,\n                fill=True,\n                fill_color=color,\n                fill_opacity=0.6\n                ).add_to(m)\n            \n    # Générer la légende avec les couleurs correspondant aux min et max\n    min_color = intensity_to_color(min_in, min_in, max_in)  # Couleur pour la valeur minimale\n    max_color = intensity_to_color(max_in, min_in, max_in)  # Couleur pour la valeur maximale\n\n    legend_html = f\"\"\"\n    &lt;div style=\"\n        position: fixed;\n        bottom: 50px;\n        left: 50px;\n        width: 200px;\n        height: 100px;\n        background-color: white;\n        border:2px solid grey;\n        z-index:9999;\n        font-size:14px;\n        padding: 10px;\n    \"&gt;\n        &lt;b&gt;Nombre de passages:&lt;/b&gt;&lt;br&gt;\n        &lt;i style=\"background: {min_color}; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; {round(min_in, 2)}&lt;br&gt;\n        &lt;i style=\"background: {max_color}; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; {round(max_in, 2)}&lt;br&gt;\n    &lt;/div&gt;\n    \"\"\"\n\n    m.get_root().html.add_child(folium.Element(legend_html))\n    # Choix de chaleur ou non\n    if style==0:\n        nom=f'intensity_{j}_{h}.html'\n        m.save(f'./Cycle3/visualisation/{jour}/intensité/{nom}')\n        return \"La carte a été générée et sauvegardée sous le nom\", nom\n    \n    else:\n        heat_data = [[coord[1], coord[0], intensity] for intensity, coord in data]\n        HeatMap(heat_data).add_to(m)\n        nom=f'intensity_{j}_{h}_heat.html'\n        m.save(f'./Cycle3/visualisation/{jour}/intensité/{nom}')\n        return\"La carte a été générée et sauvegardée sous le nom\", nom\n\n\n\nmap_trajets(j, h,jour)\n\nDescription:\nLa fonction génère une carte des trajets parcourus un jour de la semaine j et à une heure h, ainsi que la probabilité qu’il soit de nouveau parcouru (en tenant compte des archives).\nParamètres:\n\nj (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\n\nh (int): Le numéro de l’heure (entre 0 et 23) voulue.\n\njour (str): Le jour voulu (format Jour).\n\nRetourne:\n- 'La carte a été générée et sauvegardée sous le nom', nom (str, str): Un message de validation de création de la carte et le nom sous lequel elle a été enregistrée.\nCode de la fonction:\ndef map_trajets(j, h,jour):\n    \"\"\"\n    Description: \n    La fonction 'map_trajets' génère une carte des trajets parcourus un jour de la semaine j et à une heure h, ainsi que la probabilité qu'il soit de nouveau parcouru (en tenant compte des archives). \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n    - h : int\n        Le numéro de l'heure (entre 0 et 23) voulue. \n    - jour : str\n        Le nom du jour correspondant (par exemple, \"Lundi\", \"Mardi\", etc.), utilisé pour nommer les fichiers générés.\n        \n    Returns: \n    - 'La carte a été générée et sauvegardée sous le nom', nom : str, str \n        Un message de validation de création de la carte et le nom sous lequel elle a été enregistrée. \n    \"\"\"\n    trajets=All_t[j][h]\n    stations_dict = {station[0]: station[1] for station in stations}\n    if j==0:\n        N=Nl\n    elif j==1:\n        N=Nma\n    elif j==2: \n        N=Nme\n    elif j==3:\n        N=Nj\n    elif j==4:\n        N=Nv\n    elif j==5: \n        N=Ns\n    else: \n        N=Nd\n    \n    \n    ville = \"Montpellier, France\"\n    location = ox.geocode(ville)\n    graphe = ox.graph_from_point(location, dist=10000, network_type=\"all\", simplify=True)\n    carte = folium.Map(location=location, zoom_start=14)\n\n    # nb passages \n    edges_passages = defaultdict(int)\n\n    for trajet in trajets:\n        start, end = trajet[0]\n        intensity = min(trajet[1]/N, 1)\n        if start in stations_dict and end in stations_dict:\n            if start!=end:\n                lon_start, lat_start = stations_dict[start]\n                lon_end, lat_end = stations_dict[end]\n\n                # Trouver les nœuds les plus proches dans le graphe\n                start_node = ox.distance.nearest_nodes(graphe, lon_start, lat_start)\n                end_node = ox.distance.nearest_nodes(graphe, lon_end, lat_end)\n                # Calculer le chemin entre les deux nœuds\n                path = nx.shortest_path(graphe, start_node, end_node, weight=\"length\")\n\n            # Ajouter chaque segment du chemin au compteur de passages\n            for u, v in zip(path[:-1], path[1:]):\n                edges_passages[(u, v)] += intensity\n                edges_passages[(v, u)] += intensity  # Compte les passages dans les deux sens \n\n    # Couleurs en fonction du nb de passages\n    for (u, v), passage_count in edges_passages.items():\n        # Récup coordonnées des segments\n        coords = [\n            (graphe.nodes[u]['y'], graphe.nodes[u]['x']),\n            (graphe.nodes[v]['y'], graphe.nodes[v]['x'])\n        ]\n\n        # Calcul de la couleur\n        if passage_count &lt; 0.05:\n           color= \"#0000ff\" # bleu si faible\n        elif passage_count &lt; 0.15:\n            color= \"#008000\" # vert \n        elif passage_count &lt; 0.25:\n            color=\"#ffff00\" # jaune\n        elif passage_count &lt; 0.35: \n            color=\"#ff80000\" # orange \n        elif passage_count &lt; 1: \n            color=\"#ff0000\" # rouge si fort \n        else:\n            passage_count=1\n            color=\"#000000\"\n\n        # Ajouter le segment\n        folium.PolyLine(\n            locations=coords,\n            color=color,\n            weight=4,\n            opacity=0.8,\n            tooltip=f\"Pourcentage: {passage_count*100}\"\n        ).add_to(carte)\n\n    # Ajout des stations comme marqueurs\n    for station in stations:\n        try:\n            (lon, lat) = station[1]\n            for k in name_sta: \n                if k[0]==station[0]: \n                    name= k[1]\n            folium.Marker(\n                location=(lat, lon),\n                popup=f\"{name}: {lon}, {lat}\",\n                icon=folium.Icon(color=\"gray\")\n            ).add_to(carte)\n        except Exception as e:\n            print(f\"Erreur lors de l'ajout de la station {station}: {e}\")\n\n    # légende \n    legend_html = \"\"\"\n    &lt;div style=\"\n        position: fixed;\n        bottom: 50px;\n        left: 50px;\n        width: 200px;\n        height: 200px;\n        background-color: white;\n        border:2px solid grey;\n        z-index:9999;\n        font-size:14px;\n        padding: 10px;\n        \"&gt;\n        &lt;b&gt;Pourcentage de chance que le trajet soit parcouru:&lt;/b&gt;&lt;br&gt;\n        &lt;i style=\"background: #0000ff; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Très faible (&lt;5%)&lt;br&gt;\n        &lt;i style=\"background: #008000; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Faible (5%-14%)&lt;br&gt;\n        &lt;i style=\"background: #ffff00; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Modéré (15%-24%)&lt;br&gt;\n        &lt;i style=\"background: #ff8000; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Fort (25%-34%)&lt;br&gt;\n        &lt;i style=\"background: #ff0000; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Très fort (&gt; 34%)&lt;br&gt;\n        &lt;i style=\"background: #000000; width: 20px; height: 10px; display: inline-block;\"&gt;&lt;/i&gt; Sûr (1)&lt;br&gt;\n    &lt;/div&gt;\n    \"\"\"\n    carte.get_root().html.add_child(folium.Element(legend_html))\n\n    # Sauvergarder la carte\n    nom = f\"trajets_couleurs_cumulées_j{j}_h{h}.html\"\n    carte.save(f'./Cycle3/visualisation/{jour}/Trajetscouleurs/{nom}')\n    return f\"Carte enregistrée sous '{nom}'.\"\n\n\n\nFonctions utilitaires\n\n\npd_to_datetime(df, colonne_date)\n\nDescription:\nConvertit une colonne de dates dans un DataFrame pandas en un format datetime, crée une nouvelle colonne avec uniquement la date, et supprime la colonne d’origine.\nParamètres:\n- df (DataFrame) : DataFrame Pandas.\n- colonne_date (str) : Nom de la colonne à convertir.\nRetourne:\n- df (pandas.DataFrame) : Le DataFrame modifié avec une colonne ‘Date’ contenant les dates extraites, et sans la colonne d’origine colonne_date..\nCode de la fonction :\n  def pd_to_datetime(df, colonne_date):\n    df = df.dropna()\n    df[colonne_date] = pd.to_datetime(df[colonne_date])\n    df['Date'] = df[colonne_date].dt.date\n    df = df.drop(columns=[colonne_date])\n    return df\n\n\n\njour_semaine(j)\n\nDescription:\nLa fonction renvoie une liste des intensités et leurs coordonnées qui ont été mesurées à une date correspondant au jour de la semaine j.\nParamètre:\n- j (int) : Le numéro du jour de la semaine (entre 0 et 6) voulu.\nRetourne:\n- L (list) :Une liste contenant toutes les données étant rattachées à une date correspondant au jour de la semaine voulu. Les données sont l’intensité et les coordonnées auxquelles elle est liée.\nCode de la fonction:\ndef jour_semaine(j):\n    \"\"\"\n    Description: \n    La fonction 'jour_semaine' renvoie une liste des intensités et leurs coordonnées qui ont été mesurées à une date correspondant au jour de la semaine j. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n        \n    Returns:\n    - list \n        Une liste contenant toutes les données étant rattachées à une date correspondant au jour de la semaine voulu. Les données sont l'intensité et les coordonnées auxquelles elle est liée. \n    \"\"\"\n    \n    Lundi=[]\n    Mardi=[]\n    Mercredi=[]\n    Jeudi=[]\n    Vendredi=[]\n    Samedi=[]\n    Dimanche=[]\n    for i in range (len(donnees_utiles)): \n        date=datetime.strptime(donnees_utiles[i][1], '%Y-%m-%d')\n        jour=date.weekday()\n        if jour==0:\n            Lundi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==1:\n            Mardi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==2:\n            Mercredi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==3:\n            Jeudi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==4:\n            Vendredi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        elif jour==5:\n            Samedi.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n        else:\n            Dimanche.append([donnees_utiles[i][0], donnees_utiles[i][2]])\n    if j==0:\n        return Lundi\n    elif j==1:\n        return Mardi \n    elif j==2:\n        return Mercredi \n    elif j==3:\n        return Jeudi\n    elif j==4:\n        return Vendredi \n    elif j==5:\n        return Samedi \n    else:\n        return Dimanche \n\n\n\ncoor_unique(j)\n\nDescription:\nLa fonction extrait toutes les coordonnées prises sur un jour j de façon unique.\nParamètre:\n- j (int) : Le numéro du jour de la semaine (entre 0 et 6) voulu.\nRetourne:\n- L (list) : Une liste contenant toutes les coordonnées apparaissant dans les données prises un jour de la semaine j de façon unique.\nCode de la fonction:\ndef coor_unique(j):\n    \"\"\"\n    Description: \n        La fonction 'coor_unique' extrait toutes les coordonnées prises sur un jour j de façon unique. \n    \n    Paramètre: \n    j : int \n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n\n    Retourne: \n        list  \n        Une liste contenant toutes les coordonnées apparaissant dans les données prises un jour de la semaine j de façon unique. \n    \"\"\"\n    L=jour_semaine(j)\n    co=[]\n    for i in L:\n        if i[1] not in co:\n            co.append(i[1])\n    return co\n\n\n\nnb_tot_jour(j)\n\nDescription:\nLa fonction renvoie le nombre de dates comptées dans les donnnées correspondants au jour de la semaine j.\nParamètre:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\nRetourne:\n- len(D) (int): Le nombre de jour j comptés dans les données.\nCode de la fonction:\ndef nb_tot_jour(j):\n    \"\"\"\n    Description: \n    La fonction 'nb_tot_jour' renvoie le nombre de dates comptées dans les donnnées correspondants au jour de la semaine j. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n        \n    Returns: \n    - int \n        Le nombre de jour j comptés dans les données.\n    \"\"\"\n    \n    D=[]\n    for file in files:\n        with open(file, 'r', encoding='utf-8') as f:\n            lecteur = csv.reader(f, delimiter=',')  # Définir le séparateur si nécessaire\n            next(lecteur) # Ignorer l'entête \n            for ligne in lecteur: \n                dat, heur = ligne[0].split(' ')\n                date=datetime.strptime(dat, '%Y-%m-%d')\n                jour=date.weekday()\n                if jour==j:\n                    dep=ligne[1].split(' ')[0]\n                    arr=ligne[2].split(' ')[0]\n                    if dep!='' and arr!='':\n                        if dep in Sta and arr in Sta:\n                            if dat not in D:\n                                D.append(dat)\n    return len(D)\n\n\n\n\n6.2.2 Prédiction\n\n\nmean_intens(j)\n\nDescription:\nLa fonction renvoie une liste des moyennes des intensités par coordonnées mesurées à une date correspondant au jour de la semaine j.\nParamètres:\n- j (int) : Le numéro du jour de la semaine (entre 0 et 6) voulu.\nRetourne:\n- L (list) : Une liste contenant toutes les moyennes d’intensité et les coordonnées auxquelles elle sont liées.\nCode de la fonction:\ndef mean_intens(j):\n    \"\"\"\n    Description: \n    La fonction 'mean_intens' renvoie une liste des moyennes des intensités par coordonnées mesurées à une date correspondant au jour de la semaine j. \n    \n    Args: \n    j : int \n    Le numéro du jour de la semaine (entre 0 et 6) voulu. \n        \n    Returns: \n    list \n    Une liste contenant toutes les moyennes d'intensité et les coordonnées auxquelles elle sont liées. \n    \"\"\"\n    N=0 \n    L=jour_semaine(j)\n    M=[]\n    for i in L: \n        N=0 \n        sum=i[0]\n        n=0 \n        k=0 \n        for h in L:\n            if h[1]==i[1]:\n                sum+=h[0]\n                N+=1 \n        if len(M)&gt;0:\n            while n==0 and k&lt;len(M):\n                if i[1]==M[k][1]:\n                    n=1\n                k+=1\n        if n==0:\n            i[0]=sum/N\n            M.append(i)\n    return M \nExemple d’utilisation: Supposons que les données soient:\ncoordinate, date, intensity\n[3.48, 43.8], 2022-03-12, 26\n[3.47, 43.7], 2022-03-19, 32\n[3.48, 43.8], 2202-03-19, 15\nComme le 12 et le 19 mars 2022 sont des samedis: Appeler mean_intens(5) retourne [[[3.48, 43.8], 20.5], [[3.47, 43.7], 32]]\n\n\n\npoids_par_h(j)\n\nDescription:\nLa fonction compte la participation de chaque heure dans la journée. Elle donne la proportion de l’activité journalière calculée par heure pour le jour de la semaine j.\nParamètre:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\nRetourne:\n- `` (matrix): Une matrice avec pour colonne les heures et le pourcentage de l’activité journalière associée à chacune de ces heures.\nCode de la fonction:\ndef poids_par_h(j):\n    \"\"\"\n    Description: \n    La fonction 'poids_par_h' compte la participation de chaque heure dans la journée. Elle donne la proportion de l'activité journalière calculée par heure pour le jour de la semaine j. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n        \n    Returns: \n    - matrix \n        Une matrice avec pour colonne les heures et le pourcentage de l'activité journalière associée à chacune de ces heures. \n    \"\"\"\n    heures = {heure: 0 for heure in range(24)}\n    D=[]\n    for file in files:\n        with open(file, 'r', encoding='utf-8') as f:\n            lecteur = csv.reader(f, delimiter=',')  \n            next(lecteur) #ignorer l'entête \n            for ligne in lecteur: \n                dat = ligne[0].split(' ')[0]\n                heur =ligne[0].split(' ')[1]\n                date=datetime.strptime(dat, '%Y-%m-%d')\n                jour=date.weekday()\n                if jour==j:\n                    dep=ligne[1].split(' ')[0]\n                    arr=ligne[2].split(' ')[0]\n                    if dep!='' and arr!='':\n                        if dep in Sta and arr in Sta:\n                            if dat not in D:\n                                D.append(dat)\n                            heure = int(heur.split(':')[0])  # Extraire l'heure\n                            heures[heure] += 1 # Incrémenter le compteur pour cette heure\n    N=len(D)\n    H=[heures[h]/N for h in heures]\n    t=sum(H[h] for h in heures)\n    return  [[h, H[h]*100/t] for h in heures]\nExemple d’utilisation: Supposons qu’il y ait 750 trajets un jeudi dont 300 entre midi et 13h, 200 entre 18h et 19h et 250 entre 8h et 9h\nAppeler poids_par_heure retourne [[0, 0],[1, 0],[2, 0],[3, 0],[4, 0],[5, 0], [6, 0],[7, 0], [8, 33.33], [9, 0],[10, 0],[11, 0],[12, 40],[13, 0],[14, 0],[15, 0],[16, 0],[17, 0],[18, 26.66],[19, 0],[20, 0],[21, 0],[22, 0],[23, 0]]\n\n\n\ntrajets_parcourus(j, h)\n\nDescription:\nLa fonction recense les trajets ayant eut lieu un jour j à une heure h et leur occurence.\nParamètres:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\n- h (int): Le numéro de l’heure (entre 0 et 23) voulue.\nRetourne:\n- F (matrix): Une matrice avec chaque ligne de la forme [[station de départ, station d’arrivée], occurrence]\nCode de la fonction:\ndef trajets_parcourus(j,h):\n    \"\"\"\n    Description: \n    La fonction 'trajets_parcourus' recense les trajets ayant eu lieu un jour j à une heure h et leur occurence. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n    - h : int\n        Le numéro (de 0 à 23) de l'heure voulue. \n        \n    Returns: \n    - matrix \n        Une matrice avec chaque ligne de la forme [[station de départ, station d'arrivée], occurrence]\n    \"\"\"\n    D=trajets_parcourus_jour(j)\n    T=[]\n    U=[]\n    F=[]\n    for j in D:\n        H=int(j[0].split(':')[0])\n        if H==h:\n            T.append([j[1],j[2]])\n    for I in T:\n        if I not in U:\n            U.append(I) \n    for s in U:\n        c=0\n        for t in T:\n            if t==s:\n                c+=1\n        F.append([s,c])\n    return F\nExemple d’utilisation: Supposons qu’il y ait 25 trajets un jeudi entre midi et 13h faisant Comédie-Fac des sciences Appeler trajets_parcourus(3, 12) retourne une matrice dont l’une des lignes est [['Comédie', 'Fac des sciences'], 25]\n\n\n\nTRAJETS(j, h)\n\nDescription:\nLa fonction recense les trajets ayant eut lieu un jour j à une heure h.\nParamètres:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\n- h (int): Le numéro de l’heure (entre 0 et 23) voulue.\nRetourne:\n- T (matrix): Une matrice avec chaque ligne de la forme [station de départ, station d’arrivée].\nCode de la fonction:\ndef TRAJETS(j, h):\n    \"\"\"\n    Description: \n    La fonction 'TRAJETS' recense les trajets ayant eu lieu un jour j à une heure h. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n    - h : int\n        Le numéro (de 0 à 23) de l'heure voulue. \n        \n    Returns: \n    - matrix \n        Une matrice avec chaque ligne de la forme [station de départ, station d'arrivée]\n    \"\"\"\n    T=[]\n    J=[Lu, Ma, Me, Je, Ve, Sa, Di]\n    L=J[j]\n    for j in L: \n        H=int(j[0].split(':')[0])\n        if H==h: \n            T.append([j[1], j[2]])\n    return T \n\n\n\ntraj_mult(j, h)\n\nDescription:\nLa fonction recense les trajets ayant eut lieu un jour j à une heure h et leur occurrence s’ils arrivent plus de deux fois par an.\nParamètres:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\n- h (int): Le numéro de l’heure (entre 0 et 23) voulue.\nRetourne:\n- G (matrix): Une matrice avec chaque ligne de la forme [[station de départ, station d’arrivée], occurrence] uniquement si l’occurrence est supérieure à 8 ( 2 fois pas an).\nCode de la fonction:\ndef traj_mult(j, h):\n    \"\"\"\n    Description: \n    La fonction 'trajets_mult' recense les trajets ayant eu lieu un jour j à une heure h et leur occurrence s'ils arrivent plus de deux fois par an. \n        \n    Args: \n        - j : int\n            Le numéro du jour de la semaine (entre 0 et 6) voulu. \n        - h : int\n            Le numéro (de 0 à 23) de l'heure voulue. \n    \n    Returns: \n        - matrix \n        Une matrice avec chaque ligne de la forme [[station de départ, station d'arrivée], occurrence] uniquement si l'occurrence est supérieure à 8 ( 2 fois pas an).\n    \"\"\"\n    T=TRAJETS(j, h)\n    U=[]\n    F=[]\n    G=[]\n    for I in T:\n        if I not in U:\n            U.append(I) \n    for s in U:\n        c=0\n        for t in T:\n            if t==s:\n                c+=1\n        F.append([s,c])\n    for i in F:\n        if i[1]&gt;=8: # min une fois par semestre \n            G.append(i)\n    return G\n\n\n\ntrajets_parcourus_jour(j)\n\nDescription:\nLa fonction recense tous les trajets ayant eut lieu un jour j.\nParamètre:\n- j (int): Le numéro du jour de la semaine (entre 0 et 6) voulu.\nRetourne:\n- D (matrix): Une matrice avec chaque ligne de la forme [heure de départ, station de départ, station d’arrivée].\nCode de la fonction:\ndef trajets_parcourus_jour(j):\n    \"\"\"\n    Description: \n    La fonction 'trajets_parcourus_jour' recense tous les trajets ayant eut lieu un jour j. \n    \n    Args: \n    - j : int\n        Le numéro du jour de la semaine (entre 0 et 6) voulu. \n     \n    Returns: \n    - matrix\n        Une matrice avec chaque ligne de la forme [heure de départ, station de départ, station d'arrivée]. \n    \"\"\"\n    D=[]\n    for file in files:\n        with open(file, 'r', encoding='utf-8') as f:\n            lecteur = csv.reader(f, delimiter=',')  # Définir le séparateur si nécessaire\n            next(lecteur) #ignorer l'entête \n            for ligne in lecteur: \n                dat, heur = ligne[0].split(' ')\n                dep=ligne[1].split(' ')[0]\n                arr=ligne[2].split(' ')[0]\n                date=datetime.strptime(dat, '%Y-%m-%d')\n                jour=date.weekday()\n                if jour==j:\n                    if dep in Sta and arr in Sta:\n                        if dep!=arr:\n                            D.append([heur, dep, arr])\n    return D \n\n\n\n6.2.3 Video\n\n\nchemin_court(row)\n\nDescription:\nCette fonction calcule le chemin le plus court entre deux stations à l’aide du graphe routier de Montpellier. Les coordonnées géographiques des stations sont utilisées comme points de départ et d’arrivée.\nParamètres:\n- row (pandas.Series) : Une ligne issue du DataFrame contenant les coordonnées de départ et d’arrivée des trajets.\nRetourne:\n- chemin (list) : Une liste d’identifiants représentant le chemin optimal.\n- duration (float) : La durée totale en secondes pour le trajet donné.\nCode de la fonction:\n    def chemin_court(row):\n        try:\n            depart_lat, depart_lon = row['latitude_depart'], row['longitude_depart']\n            arrivee_lat, arrivee_lon = row['latitude_retour'], row['longitude_retour']\n            duration = row['Duration (sec.)']\n            \n            noeud_deb = ox.distance.nearest_nodes(G, depart_lon, depart_lat)\n            noeud_fin = ox.distance.nearest_nodes(G, arrivee_lon, arrivee_lat)\n            \n            chemin = nx.shortest_path(G, noeud_deb, noeud_fin, weight=\"length\")\n            return chemin, duration\n        except Exception as e:\n            print(f\"Erreur pour le trajet entre {row['Departure station']} et {row['Return station']}: {e}\")\n            return None, None\n    ```\n\n    **Exemple d'utilisation**:  \n    Lorsqu'une ligne du DataFrame est passée, cette fonction renvoie le chemin le plus court calculé sur la base du graphe routier et la durée du trajet.\n\n&lt;/details&gt;\n\n\n&lt;details&gt; \n    &lt;summary&gt;`init()`&lt;/summary&gt;\n\n    **Description**:  \n    Initialise l'animation en réinitialisant la position des points. Les points sont effacés pour chaque frame, leur état est remis à vide pour commencer l'animation depuis le début.\n\n    **Retourne**:  \n    - `points (list)` : Une liste d'objets `matplotlib` représentant les points à animer.  \n\n**Code de la fonction**:  \n```python\n    def init():\n        for point in points:\n            point.set_data([], [])\n        return points\nExemple d’utilisation:\nCette fonction est utilisée comme étape préliminaire pour configurer l’état de l’animation avant chaque itération.\n\n\n\nupdate(frame)\n\nDescription:\nMet à jour dynamiquement les positions des points pour chaque frame dans l’animation. Chaque point suit sa progression en fonction de la simulation temporelle et de la base de données des trajets.\nParamètres:\n- frame (int) : L’index de la frame actuelle dans la séquence d’animation.\nRetourne:\n- points (list) : Les nouvelles positions des points mis à jour pour l’animation.\nCode de la fonction:\n    def update(frame):\n        current_time = start_time + datetime.timedelta(seconds=frame * frame_duration)\n        time_text.set_text(current_time.strftime('%Y-%m-%d %H:%M:%S'))\n\n        for i, path in enumerate(paths):\n            progress = min(frame / total_frames, 1)  \n            num_nodes = int(progress * len(path))\n\n            if num_nodes &gt; 0:\n                current_node = path[num_nodes - 1]\n                x, y = G.nodes[current_node]['x'], G.nodes[current_node]['y']\n                points[i].set_data([x], [y])\n\n        return points\nExemple d’utilisation:\nChaque frame appelée dans la boucle d’animation utilise cette fonction pour déplacer les points selon la progression de leur chemin respectif.\n\n\nContexte et Explications supplémentaires\nCette section traite du fonctionnement global :\n\nLes trajets sont analysés grâce à un graphe routier avec la base OSM.\nChaque point représente un véhicule dans le réseau routier avec ses trajets correspondant à la base donnée video_avec_coord.csv.\nL’animation est synchronisée avec la base de données et simule la trajectoire temporelle."
  },
  {
    "objectID": "docu.html#la-classe-gestionnairedonnees",
    "href": "docu.html#la-classe-gestionnairedonnees",
    "title": "Documentation",
    "section": "6.3 La classe “GestionnaireDonnees”",
    "text": "6.3 La classe “GestionnaireDonnees”\nLa classe GestionnaireDonnees a été créée pour gérer le téléchargement, la lecture et le traitement des jeux de données. Elle centralise les fonctions nécessaires à la gestion des données pour notre projet, en permettant le téléchargement de fichiers depuis des URLs, l’extraction de fichiers compressés, et le chargement de fichiers CSV tout en nettoyant les données manquantes. Elle simplifie ainsi les tâches courantes liées à la gestion des données dans notre système.\nLa classe GestionnaireDonnees a été créée pour gérer le téléchargement, la lecture et le traitement des jeux de données. Elle permet de :\n\nTélécharger des fichiers depuis des URLs.\nExtraire des fichiers compressés.\nCharger des fichiers CSV tout en nettoyant les données manquantes.\n\nCette classe centralise les fonctions nécessaires à la gestion des données pour notre projet et offre une solution modulaire pour ces tâches.\n\nMéthodes\n\n\n__init__(repertoire_telechargement=\"./data\")\n\nDescription:\nInitialise le répertoire de téléchargement pour stocker les fichiers téléchargés. Si le répertoire n’existe pas, il sera automatiquement créé.\nParamètres:\n- repertoire_telechargement (str) : Le chemin où les fichiers seront téléchargés. Par défaut, “./data”.\nRetourne:\n- Rien. Cette méthode configure uniquement les attributs d’instance.\nCode de la fonction:\ndef __init__(self, repertoire_telechargement=\"./data\"):\n    self.repertoire_telechargement = repertoire_telechargement\n    os.makedirs(self.repertoire_telechargement, exist_ok=True)\nExplication:\nLe constructeur utilise la fonction os.makedirs pour s’assurer que le répertoire de téléchargement existe avant toute opération. Cela évite des erreurs lors des téléchargements futurs.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\nprint(gestionnaire.repertoire_telechargement)  # \"./data\"\n\n\n\ntelecharger_fichier(url, nom_fichier)\n\nDescription:\nTélécharge un fichier à partir d’une URL donnée et l’enregistre dans le répertoire de téléchargement.\nParamètres:\n- url (str) : L’URL du fichier à télécharger.\n- nom_fichier (str) : Le nom du fichier une fois téléchargé.\nRetourne:\n- chemin (str) : Le chemin complet du fichier téléchargé.\nCode de la fonction:\npython def telecharger_fichier(self, url, nom_fichier):     chemin = pooch.retrieve(         url=url,         known_hash=None,         fname=nom_fichier,         path=self.repertoire_telechargement     )     return chemin\nExplication:\nCette méthode utilise pooch.retrieve pour télécharger un fichier depuis une URL et le sauvegarder dans le répertoire défini. Le chemin complet du fichier est renvoyé.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\nchemin = gestionnaire.telecharger_fichier(\"https://example.com/data.csv\", \"data.csv\")\nprint(chemin)  # \"./data/data.csv\"\n\n\n\ncharger_csv(chemin_fichier, supprimer_na=True)\n\nDescription:\nCharge un fichier CSV dans un DataFrame Pandas, avec la possibilité de supprimer les lignes contenant des valeurs manquantes.\nParamètres:\n- chemin_fichier (str) : Le chemin du fichier CSV à charger.\n- supprimer_na (bool) : Indique si les lignes contenant des valeurs manquantes doivent être supprimées (par défaut, True).\nRetourne:\n- dataframe (pd.DataFrame) : Le DataFrame contenant les données du fichier CSV.\nCode de la fonction:\ndef charger_csv(self, chemin_fichier, supprimer_na=True):\n    dataframe = pd.read_csv(chemin_fichier)\n    if supprimer_na:\n        dataframe = dataframe.dropna()\n    return dataframe\nExplication:\nCette méthode permet de charger un fichier CSV dans un DataFrame Pandas tout en offrant la possibilité de supprimer les lignes contenant des données manquantes, garantissant ainsi la qualité des données.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\ndf = gestionnaire.charger_csv(\"./data/data.csv\", supprimer_na=True)\nprint(df.head())\n\n\n\nextraire_zip(chemin_zip, dossier_extraction=None)\n\nDescription:\nExtrait le contenu d’un fichier ZIP dans un répertoire spécifié.\nParamètres:\n- chemin_zip (str) : Le chemin du fichier ZIP à extraire.\n- dossier_extraction (str) : Le répertoire où les fichiers extraits seront stockés. Par défaut, les fichiers sont extraits dans un sous-dossier nommé extracted dans le répertoire de téléchargement.\nRetourne:\n- dossier_extraction (str) : Le chemin du dossier contenant les fichiers extraits.\nCode de la fonction:\ndef extraire_zip(self, chemin_zip, dossier_extraction=None):\n    if dossier_extraction is None:\n        dossier_extraction = os.path.join(self.repertoire_telechargement, \"extracted\")\n    os.makedirs(dossier_extraction, exist_ok=True)\n    with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n        zip_ref.extractall(dossier_extraction)\n    os.remove(chemin_zip)\n    return dossier_extraction\nExplication:\nCette méthode extrait un fichier ZIP dans un répertoire spécifié ou, si aucun répertoire n’est précisé, dans un sous-dossier nommé extracted. Après extraction, le fichier ZIP est supprimé pour économiser de l’espace disque.\nExemple d’utilisation:\ngestionnaire = GestionnaireDonnees()\nchemin_extraction = gestionnaire.extraire_zip(\"./data/archive.zip\")\nprint(chemin_extraction)  # \"./data/extracted/\"\n\nEn résumé, la classe GestionnaireDonnees centralise les opérations courantes liées à la gestion des données dans notre projet, rendant le processus plus fluide et réutilisable. Elle offre des méthodes pour télécharger des fichiers, charger des données à partir de CSV et extraire des fichiers ZIP, ce qui constitue la base de notre système de traitement des données."
  },
  {
    "objectID": "docu.html#introduction-1",
    "href": "docu.html#introduction-1",
    "title": "Documentation",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nLes tests jouent un rôle essentiel dans le développement du projet CycleVision3. Ils garantissent la fiabilité des modules, réduisent les risques d’erreurs et assurent une qualité élevée du code. Dans ce projet, nous avons mis l’accent sur les tests unitaires, couvrant les principaux composants fonctionnels."
  },
  {
    "objectID": "docu.html#organisation-des-tests",
    "href": "docu.html#organisation-des-tests",
    "title": "Documentation",
    "section": "7.2 Organisation des tests",
    "text": "7.2 Organisation des tests\nLes tests jouent un rôle essentiel dans le développement du projet CycleVision3 en garantissant la fiabilité des modules, en réduisant les risques d’erreurs et en assurant une qualité élevée du code. Un accent particulier a été mis sur les tests unitaires, couvrant des fonctionnalités clés telles que le traitement des données, la gestion via des classes spécifiques, la génération de cartes interactives, les prédictions algorithmiques, l’analyse statistique et la visualisation vidéo.\nPour organiser ces tests, un répertoire tests/ a été créé. Ce dernier contient plusieurs fichiers, chacun dédié à un module particulier du projet :\n\ntest_donnée.py : Tests des fonctions dans donnée.py ;\n\ntest_gestion_donnee.py : Tests de la classe GestionnaireDonnees dans gestion_donnee.py ;\n\ntest_map.py : Tests des fonctionnalités de création de cartes dans map.py ;\n\ntest_prediction.py : Tests des algorithmes de prédiction ;\n\ntest_statistique.py : Tests des fonctions statistiques de statistique.py ;\n\ntest_video.py : Tests des outils de traitement vidéo dans video.py.\n\nCette organisation garantit une bonne couverture et une séparation claire des préoccupations, tout en facilitant le suivi et le débogage des différentes fonctionnalités du projet."
  },
  {
    "objectID": "docu.html#description-des-tests-par-fichier",
    "href": "docu.html#description-des-tests-par-fichier",
    "title": "Documentation",
    "section": "7.3 Description des tests par fichier",
    "text": "7.3 Description des tests par fichier\n\n\ntest_donnée.py\n\n\nObjectif : Valider les fonctions liées au traitement et à la gestion des fichiers de données brutes.\nScénarios principaux :\n\nTéléchargement de fichiers depuis une URL spécifiée ;\nChargement et validation des fichiers CSV, incluant la vérification du contenu ;\nExtraction correcte des fichiers compressés au format ZIP.\n\nTests inclus :\n\ntest_telecharger_fichier\n\nBut : Vérifier la capacité de la méthode telecharger_fichier à télécharger un fichier depuis une URL et à le sauvegarder localement.\n\nCritères de succès :\n\nLe fichier est téléchargé sans erreurs ;\n\nLe chemin du fichier téléchargé est retourné correctement.\n\n\ntest_charger_csv\n\nBut : Tester la méthode charger_csv pour s’assurer que les fichiers CSV sont correctement chargés en tant que DataFrame.\n\nCritères de succès :\n\nLe DataFrame n’est pas vide ;\n\nLes dimensions du DataFrame et les noms des colonnes correspondent aux attentes.\n\n\ntest_extraire_zip\n\nBut : Valider la méthode extraire_zip pour extraire correctement les fichiers contenus dans une archive ZIP.\n\nCritères de succès :\n\nLes fichiers extraits sont présents dans le répertoire cible ;\n\nLe contenu de l’archive correspond aux attentes (par exemple, test.csv est extrait correctement).\n\n\n\n\n\n\n\ntest_gestion_donnee.py\n\n\nObjectif : Valider les fonctionnalités du gestionnaire de données, implémentées dans la classe GestionnaireDonnees.\nScénarios principaux :\n\nVérification de la méthode de chargement des fichiers CSV dans un DataFrame ;\nValidation des structures des données et de leur contenu après chargement.\n\nTests inclus :\n\ntest_charger_csv\n\nBut : Tester la méthode charger_csv pour s’assurer qu’elle charge correctement un fichier CSV en tant que DataFrame Pandas.\n\nCritères de succès :\n\nLe DataFrame résultant n’est pas vide ;\n\nLa structure (dimensions et colonnes) du DataFrame correspond aux attentes ;\n\nAucune erreur n’est générée lors du traitement d’un fichier CSV valide.\n\n\n\n\n\n\n\ntest_map.py\n\n\nObjectif : Valider les fonctions liées à la gestion des cartes interactives et des trajets en utilisant des graphes.\nScénarios principaux :\n\nConversion correcte des nœuds d’un trajet en coordonnées géographiques ;\nCréation d’un graphe urbain à partir de données géographiques spécifiques.\n\nTests inclus :\n\ntest_route_to_coords\n\nBut : Vérifier que la fonction route_to_coords convertit correctement une séquence de nœuds de graphe en une liste de coordonnées géographiques.\n\nCritères de succès :\n\nLes coordonnées générées correspondent exactement aux nœuds fournis ;\n\nLes données de position (latitude, longitude) sont correctement extraites des attributs du graphe.\n\n\ntest_graph_creation\n\nBut : Tester la génération d’un graphe à partir des données géographiques d’une ville en utilisant la bibliothèque OSMnx.\n\nCritères de succès :\n\nLe graphe créé contient au moins un nœud ;\n\nAucun problème de récupération des données OSM n’est rencontré.\n\n\n\n\n\n\n\ntest_prediction.py\n\n\nObjectif : Valider les fonctions liées aux prévisions d’intensité du trafic cycliste et l’analyse selon les jours spécifiques.\nScénarios principaux :\n\nVérification des valeurs renvoyées par la fonction jour_semaine pour un jour donné ;\n\nValidation de la fonction coor_unique pour extraire les coordonnées uniques en fonction d’un jour ;\n\nVérification de la cohérence de la moyenne d’intensité avec la fonction mean_intens.\n\nTests inclus :\n\ntest_jour_semaine\n\nBut : Vérifier que la fonction jour_semaine renvoie correctement les données correspondant au jour spécifique (ici, mercredi).\n\nCritères de succès :\n\nLes valeurs des données attendues doivent correspondre exactement aux données simulées.\n\n\ntest_coor_unique\n\nBut : Tester la fonction coor_unique pour extraire correctement les coordonnées uniques correspondant à un jour spécifique (ici, vendredi).\n\nCritères de succès :\n\nLes coordonnées extraites doivent correspondre exactement aux valeurs attendues.\n\n\ntest_mean_intens\n\nBut : Vérifier la bonne estimation de la moyenne d’intensité avec la fonction mean_intens pour un jour donné (ici, mercredi).\n\nCritères de succès :\n\nLa longueur des résultats doit correspondre aux valeurs attendues ;\n\nLes valeurs numériques doivent être proches des valeurs simulées avec une précision acceptable.\n\n\n\n\n\n\n\ntest_statistique.py\n\n\nObjectif : Valider le traitement des données, la sauvegarde de graphiques et la gestion d’erreurs dans le traitement des données pour les visualisations statistiques.\nScénarios principaux :\n\nVérification du traitement des données avec des opérations de groupe ;\n\nValidation de la sauvegarde d’un graphique en barres avec Matplotlib ;\n\nTest de la sauvegarde d’un graphique polaire avec Plotly ;\n\nVérification de la gestion des erreurs avec un fichier inexistant.\n\nTests inclus :\n\ntest_process_data\n\nBut : Tester la transformation des données, notamment la conversion de la colonne Departure en datetime et la création de la nouvelle colonne Date.\n\nCritères de succès :\n\nLa conversion doit réussir sans erreur ;\n\nLes valeurs dans la colonne Date doivent correspondre correctement aux dates extraites.\n\n\ntest_save_bar_chart\n\nBut : Tester la sauvegarde d’un graphique en barres avec Matplotlib.\n\nCritères de succès :\n\nVérifier que la fonction savefig a bien été appelée avec le chemin attendu.\n\n\ntest_save_polar_chart\n\nBut : Tester la sauvegarde d’un graphique polaire avec Plotly.\n\nCritères de succès :\n\nVérifier que la fonction write_html est bien appelée avec le chemin attendu.\n\n\ntest_missing_file\n\nBut : Vérifier que l’ouverture d’un fichier inexistant génère une erreur correcte (FileNotFoundError).\n\nCritères de succès :\n\nL’erreur doit être déclenchée correctement lorsqu’un fichier absent est tenté d’être lu avec pd.read_csv.\n\n\n\n\n\n\n\ntest_video.py\n\n\nObjectif : Tester le module vidéo de Cycle3/video/video.py, en se concentrant sur les aspects de traitement des données, la création et le test de graphes, la gestion de la logique avec les chemins, l’animation et la gestion des interactions avec l’utilisateur.\nScénarios principaux :\n\nVérifier la bonne conversion et le traitement de données ;\n\nTester le module de chemin court avec OSMnx et NetworkX ;\n\nSimuler la création de graphes pour analyser la carte ;\n\nVérifier la sauvegarde de vidéos avec Matplotlib ;\n\nSimuler l’interaction avec des fonctions utilisant input().\n\nTests inclus :\n\ntest_video_module\n\nBut : Charger dynamiquement le module vidéo video.py pour permettre les tests avec un environnement simulé.\n\nCritères de succès :\n\nLe module doit être chargé correctement avec importlib.util.spec_from_file_location.\n\nTester l’existence des fonctions attendues (chemin_court, init, update).\n\n\ntest_data_processing\n\nBut : Valider la bonne lecture et conversion des données de test.\n\nCritères de succès :\n\nVérifier que la colonne Departure est convertie en datetime.\n\nAssurer que le DataFrame simulé est non vide.\n\n\ntest_chemin_court\n\nBut : Simuler le calcul du chemin le plus court avec OSMnx et NetworkX.\n\nCritères de succès :\n\nVérifier que le chemin attendu est renvoyé.\n\nConfirmer la valeur de durée correspondante.\n\n\ntest_create_graph\n\nBut : Valider la création de graphes avec OSMnx.\n\nCritères de succès :\n\nVérifier que le graphe est bien de type nx.MultiDiGraph.\n\nAssurer que le graphe n’est pas vide après la création.\n\n\ntest_input_handling\n\nBut : Simuler l’interaction avec input() pour vérifier le flux de l’entrée utilisateur.\n\nCritères de succès :\n\nS’assurer que input() est bien simulé avec la valeur attendue.\n\n\ntest_save_video\n\nBut : Tester la logique de sauvegarde avec Matplotlib pour les animations.\n\nCritères de succès :\n\nVérifier que l’animation est simulée correctement sans appels non nécessaires à la fonction save.\n\nConfirmer que la sauvegarde n’a pas été appelée avant la logique de test."
  },
  {
    "objectID": "docu.html#résultats-des-tests",
    "href": "docu.html#résultats-des-tests",
    "title": "Documentation",
    "section": "7.4 Résultats des tests",
    "text": "7.4 Résultats des tests\nTous les modules ont été testés avec succès, et les bugs identifiés ont été corrigés. Une couverture élevée des fonctionnalités a été obtenue grâce à une série de tests unitaires exécutés avec l’outil pytest.\nLa commande suivante permet d’exécuter tous les tests :\npytest tests/"
  },
  {
    "objectID": "docu.html#conclusion",
    "href": "docu.html#conclusion",
    "title": "Documentation",
    "section": "7.5 Conclusion",
    "text": "7.5 Conclusion\nLes tests réalisés ont permis de valider la majorité des fonctionnalités critiques du projet. Toutefois, des améliorations supplémentaires pourraient être envisagées, notamment pour couvrir des cas d’utilisation moins fréquents ou des scénarios extrêmes."
  },
  {
    "objectID": "docu.html#pour-map_trajet_bd.py",
    "href": "docu.html#pour-map_trajet_bd.py",
    "title": "Documentation",
    "section": "8.1 Pour map_trajet_BD.py",
    "text": "8.1 Pour map_trajet_BD.py\nAprès avoir exécuté la commande mprof run, nous avons obtenu les graphiques suivants. Le premier a été généré en traçant environ une centaine de trajets, tandis que le second illustre un tracé comportant environ 600 trajets.\n\n \n\nDans cette section du code, on observe qu’un tracé de 500 trajets différents entraîne un écart de temps de 175 secondes, soit presque 3 minutes. Le temps d’exécution du fichier varie donc entre 1 minute (pour les jours avec moins de trajets) et 3 minutes (pour les jours les plus chargés). En ce qui concerne la mémoire utilisée, elle reste stable autour de 800 mébioctets (environ 800 Mo) par fichier Python. Ce chiffre est cohérent avec les machines modernes, mais pourrait devenir un facteur limitant sur des machines plus anciennes."
  },
  {
    "objectID": "docu.html#pour-vidéo.py",
    "href": "docu.html#pour-vidéo.py",
    "title": "Documentation",
    "section": "8.2 Pour vidéo.py",
    "text": "8.2 Pour vidéo.py\nAprès avoir exécuté la commande mprof run, les graphiques suivants ont été obtenus. Ceux-ci correspondent à des fichiers avec un nombre variable de trajets, allant de 100 à 600 trajets.\n\n \n\n\n \n\nIci, la consommation de mémoire reste similaire à celle du fichier précédent. Cependant, la différence réside dans le temps d’exécution. Malgré les tentatives d’optimisation du script, celui-ci s’exécute en environ 130 à 225 secondes pour charger une vidéo en format .mp4."
  },
  {
    "objectID": "docu.html#conclusion-1",
    "href": "docu.html#conclusion-1",
    "title": "Documentation",
    "section": "8.3 Conclusion",
    "text": "8.3 Conclusion\nConcernant l’efficacité temporelle, plusieurs problèmes ont été rencontrés lors des premiers essais. Pour y remédier, des outils tels que ThreadPoolExecutor et l’utilisation de cache ont été mis en place. De plus, un choix stratégique a été fait en privilégiant l’importation directe des bases de données, plutôt que de les appeler via des requêtes HTTP avec requests, afin d’améliorer la vitesse d’exécution."
  },
  {
    "objectID": "docu.html#clone-du-répertoire-github",
    "href": "docu.html#clone-du-répertoire-github",
    "title": "Documentation",
    "section": "9.1 Clone du répertoire Github",
    "text": "9.1 Clone du répertoire Github\nPour accéder au projet et à sa structure, commencez par cloner notre répertoire GitHub.\ngit clone https://github.com/mscaia/PROJ_HAX712X.git\ncd ./PROJ_HAX712X"
  },
  {
    "objectID": "docu.html#installation-des-packages-nécessaires",
    "href": "docu.html#installation-des-packages-nécessaires",
    "title": "Documentation",
    "section": "9.2 Installation des packages nécessaires",
    "text": "9.2 Installation des packages nécessaires\nOn vous conseille de créer un environnement virtuel, il permet d’isoler les dépendances d’un projet, d’éviter les conflits de versions, et de garantir un contrôle simple sur les paquets installés. Il assure la reproductibilité du projet, facilite la gestion des dépendances, et protège votre système.\nconda create --name Cycle3 python=3.9.18\nconda activate Cycle3\nEnsuite, installez les packages nécessaires pour faire fonctionner le projet :\npip install -r requirements.txt\nAprès cette commande, l’environnement virtuel Cycle3 occupera environ 1 Go de votre espace. Vous êtes maintenant prêt à utiliser notre projet avec tous les packages nécessaires."
  },
  {
    "objectID": "docu.html#comment-lancer-certains-scripts",
    "href": "docu.html#comment-lancer-certains-scripts",
    "title": "Documentation",
    "section": "9.3 Comment lancer certains scripts",
    "text": "9.3 Comment lancer certains scripts\nTous les scripts doivent être exécutés depuis le terminal. Assurez-vous que vous êtes dans la racine du projet, nommée PROJ_HAX712X. Dans les chemins relatifs, ./fait référence à la racine du projet.\n\n9.3.1 Utilisation de notre class pour télécharger les données\nTéléchargez les données nécessaires pour travailler (nous avons choisi de les laisser sur GitHub) :\n python ./src/donnée.py\n\n\n9.3.2 Voir nos éléments d’analyse de données\nPour voir les éléments d’analyse des données, lancez la commande suivante :\npython ./Cycle3/analyse_donnee/statistique.py\nCertaines sorties sont affichées dans le terminal (avec print), mais les graphiques sont disponibles dans le répertoire suivant :\ncd ./docs/projet1_files/figure-html\nVous y trouverez des fichiers .html et .png.\n\n\n9.3.3 Visualisation des cartes\nDans le dossier ./Cycle3/map/, vous trouverez trois fichiers .py différents pour travailler avec les cartes :\n\ncarte.py\n\nAffiche la disponibilité en temps réel des vélos dans les stations Vélomagg de Montpellier.\n python ./Cycle3/map/carte.py \nLa carte générée est sauvegardée dans ./docs/montpellier_bike_stations_map.html.\n\nmap.py\n\nEffectue une simulation de trajet. L’interactivité se fait via le terminal\n python ./Cycle3/map/map.py \nLa carte générée est sauvegardée dans ./Cycle3/visualisation/carte_montpellier_trajet.html\n\n\n9.3.4 Création d’une vidéo\nNous avons lié les scripts ./Cycle3/map/map_trajet_BD.py et ./Cycle3/vidéo/vidéo.py pour analyser les trajets d’un jour spécifique et les transformer en vidéo.\n\nChoisir le jour dans map_trajet_BD.py\n\nLancez la commande suivante pour sélectionner le jour que vous souhaitez analyser. Vous aurez la possibilité de tracer ou non les trajets, et de définir le nombre de trajets à afficher.\n python ./Cycle3/map/map_trajet_BD.py\nLa carte générée est sauvegardée dans ./Cycle3/visualisation/carte_montpellier_trajet_via_BD.html\n\nCréation de la vidéo\n\nAttention : Ce processus peut être long. Veuillez vous référer à la section 8. Analyse des performances de la documentation pour plus d’informations. Lancez la commande suivante pour créer la vidéo :\n python ./Cycle3/vidéo/vidéo.py\nVous pourrez choisir le nombre de trajets à afficher. La vidéo générée sera sauvegardée dans ./Cycle3/visualisation/simulation_trajets.mp4.\n\n\n9.3.5 Utilisation de la prédiction\nPour lancer notre script sur la prédiction :\n./Cycle3/prediction/prediction.py"
  },
  {
    "objectID": "docu.html#création-et-utilisation-du-site",
    "href": "docu.html#création-et-utilisation-du-site",
    "title": "Documentation",
    "section": "9.4 Création et utilisation du site",
    "text": "9.4 Création et utilisation du site\nVoici quelques étapes pour la création et l’utilisation d’un site Quarto comme celui que nous avons créé.\n\nInstallation de Quarto\n\nTéléchargez et installez Quarto depuis quarto.org/download. Prenez bien soin d’ajouter Quarto à vos variables d’environnements.\n\nCréation du projet\n\nPuis, ouvrez un terminal et exécutez les commandes suivantes :\nmkdir docs\ncd docs\nquarto create-project nom_du_projet --type website\n\nAjout de contenu\n\n\nAjoutez des fichiers .qmd dans le dossier docs pour enrichir le site.\nModifiez le fichier _quarto.yml pour personnaliser la structure et les paramètres du site.\n\n\nPrévisualisation locale\n\nLe site peut ensuite être lancé via la commande suivante dans le répertoire ./docs/.\n quarto preview\n\nDéploiement sur GitHub\n\nDans les paramètres de votre projet Github, allez dans GitHub Pages puis dans la section Build and Deployment. Dans l’onglet “Source” sélectionnez Deploy from a branch et en dessous sélectionnez la branche main et le dossier docs. Vous pouvez ensuite taper les commandes suivantes (toujours dans le répertoire ./docs/) dans un terminal :\n quarto render\nLe site sera alors déployé à votre prochain push !"
  },
  {
    "objectID": "docu.html#suppression-de-lenvironnement-virtuel",
    "href": "docu.html#suppression-de-lenvironnement-virtuel",
    "title": "Documentation",
    "section": "9.5 Suppression de l’environnement virtuel",
    "text": "9.5 Suppression de l’environnement virtuel\nSi vous n’avez plus besoin de l’environnement virtuel et souhaitez le supprimer définitivement, suivez les étapes ci-dessous :\n\nDésactivez l’environnement\n\n conda deactivate\n\nSupprimez l’environnement Conda\n\nconda env remove --name Cycle3\n\nVérifiez que l’environnement a été supprimé\n\nconda env list\nSi l’environnement Cycle3 a été correctement supprimé, vous ne le verrez plus dans la liste des environnements disponibles."
  },
  {
    "objectID": "maps.html",
    "href": "maps.html",
    "title": "Visualisation cartographique",
    "section": "",
    "text": "Découvrez ci-dessous notre application, développée avec Shiny, qui offre une interface intuitive pour visualiser les trajets qui ont été effectués par les usagers au cours de l’année 2024.\n\n\n\nL’application Shiny est en ligne ici : Accéder à l’application Shiny"
  },
  {
    "objectID": "maps.html#carte-interactive-des-trajets",
    "href": "maps.html#carte-interactive-des-trajets",
    "title": "Visualisation cartographique",
    "section": "",
    "text": "Découvrez ci-dessous notre application, développée avec Shiny, qui offre une interface intuitive pour visualiser les trajets qui ont été effectués par les usagers au cours de l’année 2024.\n\n\n\nL’application Shiny est en ligne ici : Accéder à l’application Shiny"
  },
  {
    "objectID": "maps.html#cartes-prévisionnelles",
    "href": "maps.html#cartes-prévisionnelles",
    "title": "Visualisation cartographique",
    "section": "Cartes prévisionnelles",
    "text": "Cartes prévisionnelles\n\nVoici d’autres cartes illustrant les prévisions des stations les plus fréquentées et des trajets les plus empruntés pour chaque jour et chaque heure de la semaine :\n\nLa première carte présente une moyenne journalière des passages aux stations de vélos, affichée avec un effet de chaleur (c’est une heatmap).\nLa deuxième montre les mêmes données, mais détaillées par heure et sans l’effet de chaleur.\nEnfin, la troisième montre la fréquence des trajets effectués tout au long de la semaine, avec une vue détaillée par jour et par heure.\n\nL’ensemble de ces résultats ont été obtenus en calculant des moyennes à partir des données présentées sur la page d’accueil. Par défaut, les cartes sont réglées pour afficher la version du lundi à minuit.\n\n\n\n\n\n\n\nCarte des intensités moyennes\n\n\nSélectionner un jour :  Lundi Mardi Mercredi Jeudi Vendredi Samedi Dimanche  Afficher la carte\n\n\n\n\n\n\nCarte des intensités\n\n\nSélectionner un jour :  Lundi Mardi Mercredi Jeudi Vendredi Samedi Dimanche \nSélectionner une heure :  00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00 18:00 19:00 20:00 21:00 22:00 23:00  Afficher la carte\n\n\n\n\n\n\nCarte des trajets\n\n\nSélectionner un jour :  Lundi Mardi Mercredi Jeudi Vendredi Samedi Dimanche \nSélectionner une heure :  00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00 18:00 19:00 20:00 21:00 22:00 23:00  Afficher la carte"
  }
]